{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low luminosity transient searches\n",
    "\n",
    "This notebook is prepared by Viraj Karambelkar (vk2588@columbia.edu) for the LSST CCA Summer School 2025, conducted at the Center for Computational Astrophysics from July 28 to August 8, 2025.\n",
    "\n",
    "## Introduction\n",
    "This module demonstrates how to study low-luminosity transients using time-domain surveys.\n",
    "\n",
    "In this notebook, we will first review the landscape of low-luminosity transients, and attempt to find a low-luminosity transient by filtering through real ZTF alerts. We will look at examples of filtering alert streams to find candidate transients, followed by cross-matching with galaxy catalogs to identify potential host galaxies and estimate the absolute magnitudes of the candidates, and leverage the photometric properties to identify the transient of interest.  Finally, we will look at how archival photometric data can be used to study precursor emission and identify progenitors of transients in nearby galaxies.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the landscape of low-luminosity transients\n",
    "- Filter alert streams to find candidate low-luminosity transients\n",
    "- Explore galaxy catalogs to identify potential host galaxies\n",
    "- Use color and lightcurve information to examine the diversity of low luminosity transients.\n",
    "- Understand how archival data can be used to study precursor emission and identify the progenitors of transients in nearby galaxies\n",
    "\n",
    "This notebook can be done alone or in groups. However, there are three breakout discussion activities that you should do in groups, and discuss your findings with everyone.\n",
    "\n",
    "## Required packages\n",
    "pandas <br>\n",
    "alerce <br>\n",
    "astropy <br>\n",
    "psycopg <br>\n",
    "tqdm <br>\n",
    "matplotlib <br>\n",
    "astroquery <br>\n",
    "numpy <br>\n",
    "matplotlib <br>\n",
    "emcee <br>\n",
    "corner <br>\n",
    "\n",
    "If you already have these packages installed, try executing the next cell - if you get no errors, your imports are likely good to go. If not, try installing these preferred versions with `pip`.\n",
    "\n",
    "Preferred versions : <br>\n",
    "numpy >=2.0.0 <br>\n",
    "matplotlib>=3.10.0 <br>\n",
    "astropy >= 7.0.0 <br>\n",
    "pandas >= 2.2.1 <br>\n",
    "psycopg == 3.2.9 <br>\n",
    "astroquery == 0.4.10 <br>\n",
    "tqdm == 4.67.1 <br>\n",
    "emcee == 3.1.6 <br>\n",
    "corner == 2.2.3 <br>\n",
    "\n",
    "\n",
    "## External files\n",
    "Provided in the files subdirectory\n",
    "- `landscape.jpg` : A luminosity-timescale plot from Cai et al. 2022\n",
    "- `mist_tracks/` : MIST stellar evolutionary tracks\n",
    "- `glade_galaxies.csv` : Downloaded GLADE galaxies, in case online query fails\n",
    "- `all_ztf_alerts.csv` : Downloaded ZTF alerts, in case online query fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:13:14.314844Z",
     "start_time": "2025-07-27T23:13:06.971691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kde/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from alerce.core import Alerce\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.time import Time\n",
    "import psycopg\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astroquery.vizier import Vizier\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "import matplotlib\n",
    "import emcee\n",
    "from astropy.modeling.physical_models import BlackBody\n",
    "import corner\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    A function to set matplotlib parameters so the plots look decent.\n",
    "    \"\"\"\n",
    "    matplotlib.rcParams['xtick.minor.size'] = 6\n",
    "    matplotlib.rcParams['xtick.major.size'] = 8\n",
    "    matplotlib.rcParams['ytick.major.size'] = 8\n",
    "    matplotlib.rcParams['ytick.minor.size'] = 6\n",
    "    matplotlib.rcParams['lines.linewidth'] = 1.0\n",
    "    matplotlib.rcParams['axes.linewidth'] = 1.0\n",
    "    matplotlib.rcParams['font.size']= 18\n",
    "    matplotlib.rcParams['font.family']= 'sans-serif'\n",
    "    matplotlib.rcParams['xtick.major.width']= 1.5\n",
    "    matplotlib.rcParams['ytick.major.width']= 1.5\n",
    "    matplotlib.rcParams['ytick.direction']='in'\n",
    "    matplotlib.rcParams['xtick.direction']='in'\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The landscape of low luminosity transients\n",
    "\n",
    "Here is a luminosity-timescale plot (from [Cai et al. 2022](https://www.mdpi.com/2218-1997/8/10/493))\n",
    "\n",
    "![Luminosity timescale plot](files/landscape.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will focus on transients with peak absolute magnitudes lower than -16 and that are not necessarily fast (i.e. $\\tau_{\\rm{0.1dex}}>10$ days). This includes the following classes of transients ---\n",
    "\n",
    "- Luminous Red Novae (LRNe): believed to be stellar mergers of massive stars.\n",
    "- Intermediate Luminosity Red Transients (ILRTs): Unclear origins, possibly electron-capture supernovae in AGB stars.\n",
    "- Luminous Blue Variable (LBV) outbursts : Massive stars undergoing outbursts.\n",
    "- Classical novae : Have the lowest luminosities in this category, and are thermonuclear explosions on the surface of white dwarfs.\n",
    "- Low luminosity core-collapse supernovae : Unclear origins, possibly representing explosions of the lowest mass stars that can undergo core-collapse.\n",
    "- Low luminosity Type Iax supernovae : Unusual thermonuclear supernovae that are believed to originate from partial deflagrations of accreting white dwarfs that do not fully detonate the white dwarf.\n",
    "- Calcium-rich transients : Unclear origins, show unusually strong calcium emission lines in their spectra.\n",
    "- Other theoretically supported transients that are yet to be observationally confirmed, such as electron-capture supernovae, direct collapse of a star to a black hole, and so on.\n",
    "\n",
    "Let's understand the detectability horizons for these transients.\n",
    "\n",
    "Problem 1 : Plot the detection horizon distance (i.e. maximum distance out to which a transient can be detected) as a function of its r-band absolute magnitude, for ZTF (limiting magnitude = 20.5 mag) and LSST (limiting magnitude = 24 mag). Keep in mind milestone-distances of the Magellanic Clouds (~ 50 kpc), M31 (~ 1 Mpc), and the Virgo Cluster (~ 20 Mpc). Examine the differences in detectability between ZTF and LSST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:13:14.372102Z",
     "start_time": "2025-07-27T23:13:14.364691Z"
    }
   },
   "outputs": [],
   "source": [
    "abs_mags = np.linspace(-6, -16, 50)\n",
    "ztf_lim_mag = 20.5\n",
    "lsst_lim_mag = 24.0\n",
    "\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you go about identifying these low-luminosity transients in a survey like ZTF?\n",
    "For starters, it would be great if we could determine the absolute magnitudes of the transients. To do this, we need to know the distance to the transient. We can use galaxy catalogs to identify potential host galaxies, and then use the redshift of the host galaxy to calculate the distance.\n",
    "\n",
    "Fortunately, there are many galaxy redshift surveys that have compiled galaxy catalogs in the local universe. Some catalogs that are commonly used in transient science are ---\n",
    "- GLADE galaxy catalog : https://arxiv.org/abs/2110.06184\n",
    "- CLU galaxy catalog : https://arxiv.org/abs/1710.05016\n",
    "- NED Local Volume Survey catalog : https://arxiv.org/abs/2306.06271\n",
    "- DESI redshift catalog : https://ned.ipac.caltech.edu/Documents/Holdings/Sets/DESI-EDR\n",
    "\n",
    "### Breakout 1\n",
    "There are many different galaxy catalogs available in the market. Take some time to find what catalogs exist, read their specifications, and understand their differences. What are some considerations that you would need to make in order to choose an appropriate galaxy catalog? Which ones will be the most relevant for the Rubin era?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, cross-matching to galaxy catalogs and filtering only sources with the luminosities of interest results in a substantial reduction of alert volume. However, we still need to filter out other contaminants such as stars, AGNs, incorrect host-associations, image-subtraction artifacts, etc. Let us now dive into real ZTF data and try identifying a Luminous Red Nova."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identifying a Luminous Red Nova in ZTF data\n",
    "\n",
    "In this part, let us search through ZTF alerts for a Luminous Red Nova (LRN). As a reminder, LRNe are transients believed to originate in stellar mergers following common-envelope evolution in binary systems. They are also termed as \"gap-transients\", because they have luminosities between classical novae and supernovae. Extragalactic LRNe have massive progenitors, and have peak absolute magnitudes between -10 and -16. They also have a characteristic double-peaked lightcurve that starts off blue (sometimes showing a pronounced blue peak) and then evolves to redder colors over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by examining the ZTF alert stream from the first seven days of February 2021. We will use the ALerce alert broker to query for ZTF alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T23:44:57.329947Z",
     "start_time": "2025-07-16T23:44:57.322995Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date = '2021-02-01T00:00:00'\n",
    "end_date = '2021-02-07T00:00:00'\n",
    "\n",
    "start_date_mjd = Time(start_date).mjd\n",
    "end_date_mjd = Time(end_date).mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us find out how many alerts were first detected in this period. We will use the ALeRCE database to do this, as it contains all ZTF alerts from 2018 onwards, and is available through a public API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:59:04.832592Z",
     "start_time": "2025-07-17T08:59:04.569328Z"
    }
   },
   "outputs": [],
   "source": [
    "# These credentials is publicly sourced from https://github.com/alercebroker/usecases/blob/master/alercereaduser_v4.json, in case\n",
    "# you were (rightly) panicking about potential security breaches\n",
    "params =  {\n",
    "        \"dbname\" : \"ztf\",\n",
    "        \"user\" : \"alerceread\",\n",
    "        \"host\": \"54.205.99.47\",\n",
    "        \"password\" : \"w*C*u8AXZ4e%d+zv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T00:28:47.534521Z",
     "start_time": "2025-07-17T00:28:44.389879Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1d/r0f_wd9x10v1pb53kt5hsjg00000gn/T/ipykernel_82614/654809605.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alerts first detected in the period 2021-02-01T00:00:00 to 2021-02-07T00:00:00: 459620\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg.connect(dbname=params['dbname'], user=params['user'], host=params['host'], password=params['password'])\n",
    "# Query the database to get the number of alerts in the specified period\n",
    "query = \"select object.oid from object where object.firstMJD > 59246 and object.firstMJD < 59253;\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(f\"Number of alerts first detected in the period {start_date} to {end_date}: {len(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK there are almost 500k alerts that were first detected in these seven days. We need to filter through them to identify a Luminous Red Nova that erupted during this time. Let us do that using the Alerce public API.\n",
    "\n",
    "First, query all alerts that had at least three ZTF detections, and were first detected during this period. (You might have to run the query in batches.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T00:08:43.710041Z",
     "start_time": "2025-07-17T00:08:25.223486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query all ZTF alerts from ALeRCE in this period using the API. If this times out or does not work for some reason,\n",
    "# uncomment and run the next block that has reads in the alerts from a pre-downloaded file.\n",
    "\n",
    "alerce = Alerce()\n",
    "query_ended = False\n",
    "counter = 1\n",
    "all_alerts = pd.DataFrame()\n",
    "while not query_ended:\n",
    "    alerts = alerce.query_objects(\n",
    "        format='pandas',\n",
    "        firstmjd=[start_date_mjd, end_date_mjd],\n",
    "        page=counter,\n",
    "        page_size=10000,\n",
    "        ndet = [3, 99999],\n",
    "    )\n",
    "    if (len(alerts) == 0) or (counter > 10):\n",
    "        query_ended = True\n",
    "    all_alerts = pd.concat([all_alerts, alerts], ignore_index=True)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you cannot query the alerts from the Alerce API\n",
    "# all_alerts = pd.read_csv(\"files/all_ztf_alerts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:14:23.269503Z",
     "start_time": "2025-07-27T23:14:23.265924Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Retrieved a total of {len(all_alerts)} alerts first detected in the period {start_date} to {end_date} \"\n",
    "      f\"with the criteria : At least 3 detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out stars, using the 'stellar' column from alerce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:14:17.362777Z",
     "start_time": "2025-07-27T23:14:17.358238Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "print(f\"After filtering out stars, we have {len(all_alerts)} alerts left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are interested in low luminosity transients, we need a way to identify the redshift of the transient. This is where galaxy catalogs come in.\n",
    "\n",
    "Here, let us cross-match this list to the GLADE galaxy catalog, which is available on vizier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T00:13:06.642693Z",
     "start_time": "2025-07-17T00:13:06.593444Z"
    }
   },
   "outputs": [],
   "source": [
    "vizier = Vizier(columns=['RAJ2000', 'DEJ2000', 'GLADE_ID', 'GLADE_RA', 'GLADE_DEC', 'GLADE_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:44:31.720445Z",
     "start_time": "2025-07-17T03:44:31.656899Z"
    }
   },
   "outputs": [],
   "source": [
    "all_alerts_crds = SkyCoord(ra=all_alerts['meanra'], dec=all_alerts['meandec'], unit='deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T05:05:03.022978Z",
     "start_time": "2025-07-17T05:00:08.277330Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [04:54<00:00,  7.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Note : There is a chance that this block fails to execute because Vizier times out your connection, particularly if many people are querying Vizier at the same time.\n",
    "# astroquery does cache successful queries, so you can try rerunning this block a few times and see if the query finishes.\n",
    "# If you cannot get it to work, fret not : we have downloaded the relevant subset of the galaxy catalog and stored it in the files/glade_galaxies.csv file.\n",
    "# The next cell block has the necessary code to read and xmatch to this catalog.\n",
    "xmatched_alerts = pd.DataFrame()\n",
    "all_galaxies_combined = pd.DataFrame()\n",
    "for i in tqdm(range(0, len(all_alerts_crds), 1000)):\n",
    "    alerts_batch = all_alerts_crds[i:i+1000]\n",
    "    alerts_sub_df = all_alerts.iloc[i:i+1000]\n",
    "    result = Vizier.query_region(alerts_batch, radius=70*u.arcsec, catalog='VII/281/glade2')\n",
    "    if len(result) == 0:\n",
    "        all_galaxies = pd.DataFrame()\n",
    "    else:\n",
    "        # Concatenate the new results to the existing dataframe\n",
    "        xmatch_sub_df = alerts_sub_df.iloc[result[0]['_q'] - 1]\n",
    "        # sideways concatenate the GLADE results to the existing dataframe\n",
    "        glade_df = result[0].to_pandas()\n",
    "        all_galaxies = glade_df\n",
    "        xmatch_sub_df = pd.concat([xmatch_sub_df.reset_index(drop=True), glade_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        xmatched_alerts = pd.concat([xmatched_alerts, xmatch_sub_df], ignore_index=True)\n",
    "    all_galaxies_combined = pd.concat([all_galaxies_combined, all_galaxies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:16:55.939118Z",
     "start_time": "2025-07-29T19:16:55.931228Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Uncomment and run this block if the previous query does not work\n",
    "# all_galaxies_combined = pd.read_csv('files/glade_galaxies.csv')\n",
    "# galaxies_crds = SkyCoord(ra=all_galaxies_combined['RAJ2000'], dec=all_galaxies_combined['DEJ2000'], unit=\"deg\")\n",
    "# idx, d2d, _ = all_alerts_crds.match_to_catalog_sky(galaxies_crds)\n",
    "# match_mask = (d2d.to(u.arcsec).value < 70)\n",
    "# xmatched_alerts = all_alerts[match_mask]\n",
    "# xmatched_alerts = pd.concat([xmatched_alerts.reset_index(drop=True), all_galaxies_combined.iloc[idx[match_mask]].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:14:49.069660Z",
     "start_time": "2025-07-27T23:14:49.065462Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Cross-matched {len(xmatched_alerts)} alerts with the GLADE galaxy catalog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Already down by a factor of 250. However this list includes several fake-associations that are likely not associated with the galaxy, but just happen to be within 70 arcsec. Let's calculate the physical distance between the transient position and the galaxy position, and filter out those that are further than 10 kpc from the galaxy.\n",
    "\n",
    "Note that I just made up the 10 kpc number : in practice this will depend on the types of transients you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:16:27.428679Z",
     "start_time": "2025-07-27T23:16:27.418213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate physical distance and filter out sources that are more than 10kpc from the galaxy centers\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK let us now query the lightcurves of these transients and use the distances to the host galaxies to calculate their peak absolute magnitudes in ZTF data.\n",
    "\n",
    "Herea are some helper functions to query the lightcurves, thumbnails and plot them (copied from the module on GW searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T22:17:26.256593Z",
     "start_time": "2025-07-27T22:17:26.202552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Color config for filters\n",
    "colors = {1: \"green\", 2: \"red\"}\n",
    "labels = {1: 'g', 2: 'r'}\n",
    "markers = {1: 'o', 2: 's'}\n",
    "sizes = {1: 30, 2: 60}\n",
    "\n",
    "def plotStamps(oid, lc_det, client):\n",
    "    # Find first detection with a valid stamp\n",
    "    if \"has_stamp\" not in lc_det.columns or lc_det[\"has_stamp\"].sum() == 0:\n",
    "        print(f\"⚠️ No stamp available for {oid}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        candid = lc_det.loc[lc_det.has_stamp].sort_values(\"mjd\").candid.iloc[0]\n",
    "        stamps = client.get_stamps(oid, candid, format='HDUList')\n",
    "        science, ref, difference = stamps[0].data, stamps[1].data, stamps[2].data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch stamps for {oid}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Plot the cutouts\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "    titles = [\"Science\", \"Reference\", \"Difference\"]\n",
    "    images = [science, ref, difference]\n",
    "\n",
    "    for i in range(3):\n",
    "        img = np.log1p(images[i])  # log scale with log1p for stability\n",
    "        _, med, std = sigma_clipped_stats(img, sigma=3.0)\n",
    "        ax[i].imshow(img, cmap='viridis', origin='lower')\n",
    "        ax[i].set_title(titles[i])\n",
    "        ax[i].axis(\"off\")\n",
    "\n",
    "    ax[0].set_title(f\"{oid}, candid: {candid}\", loc='left', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plotLC(oid, SN_det, SN_nondet):\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for fid in [1, 2]:\n",
    "        mask = SN_det.fid == fid\n",
    "        if np.sum(mask) > 0:\n",
    "            ax.errorbar(\n",
    "                SN_det[mask].mjd, SN_det[mask].magpsf,\n",
    "                yerr=SN_det[mask].sigmapsf,\n",
    "                c=colors[fid], label=labels[fid],\n",
    "                marker=markers[fid], linestyle='none'\n",
    "            )\n",
    "\n",
    "        mask = (SN_nondet.fid == fid) & (SN_nondet.diffmaglim > -900)\n",
    "        if np.sum(mask) > 0:\n",
    "            ax.scatter(\n",
    "                SN_nondet[mask].mjd, SN_nondet[mask].diffmaglim,\n",
    "                c=colors[fid], alpha=0.5, marker='v',\n",
    "                label=f\"lim.mag. {labels[fid]}\", s=sizes[fid]\n",
    "            )\n",
    "\n",
    "    ax.set_title(oid, fontsize=20)\n",
    "    ax.set_xlabel(\"MJD\", fontsize=16)\n",
    "    ax.set_ylabel(\"Apparent magnitude\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_lc_data(oid, client, doLC=False, doStamps=False):\n",
    "    results = {\"oid\": oid}\n",
    "\n",
    "    try:\n",
    "        lc_det = client.query_detections(oid, format='pandas').sort_values(\"mjd\")\n",
    "        results[\"lc_det\"] = lc_det\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not fetch detections for {oid}: {e}\")\n",
    "        lc_det = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        lc_nondet = client.query_non_detections(oid, format='pandas').sort_values(\"mjd\")\n",
    "        results[\"lc_nondet\"] = lc_nondet\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not fetch non-detections for {oid}: {e}\")\n",
    "        lc_nondet = pd.DataFrame()\n",
    "\n",
    "    # Plot light curve\n",
    "    if doLC and not lc_det.empty and not lc_nondet.empty:\n",
    "        plotLC(oid, lc_det, lc_nondet)\n",
    "\n",
    "    # Plot stamps\n",
    "    if doStamps and not lc_det.empty:\n",
    "        plotStamps(oid, lc_det, client)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:18:23.895200Z",
     "start_time": "2025-07-27T23:18:23.891261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the peak magnitudes and store all lightcurves\n",
    "min_mags, all_lcs = [], {}\n",
    "for ind in tqdm(range(len(xmatched_alerts))):\n",
    "    ## Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:20:02.827066Z",
     "start_time": "2025-07-27T23:20:02.822989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the real bogus scores for the sources\n",
    "rbscores = []\n",
    "for ind in tqdm(range(len(xmatched_alerts))):\n",
    "    ## Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T06:30:34.291458Z",
     "start_time": "2025-07-17T06:30:34.284733Z"
    }
   },
   "outputs": [],
   "source": [
    "xmatched_alerts['min_mag'] = min_mags\n",
    "xmatched_alerts['rb'] = rbscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the candidates that you obtain after absolute magnitude filtering. Is there additional filtering you can do with which you can get the number of candidates lower than 10?\n",
    "\n",
    "Let's add some more quality cuts based on the real-bogus score, the minimum apparent magnitude, total duration, and minimum number of detections (NOTE we can only add the last criterion because we are doing an archival search. If you are interested in finding these sources in realtime and when they are young, you would not want to filter on number of detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:22:42.829909Z",
     "start_time": "2025-07-27T23:22:42.822725Z"
    }
   },
   "outputs": [],
   "source": [
    "## Filter sources with peak apparent magnitude brighter than 20 mag, real-bogus score greater than 0.5,\n",
    "## at least 10 detections, and the total duration lower than a thousand days.\n",
    "\n",
    "xmatched_alerts_real = xmatched_alerts[## Your code here\n",
    "     ].reset_index(drop=True)\n",
    "\n",
    "print(f\"After filtering out sources with min_mag > 20 and rb < 0.5, we have {len(xmatched_alerts_real)} alerts left.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T07:16:51.342115Z",
     "start_time": "2025-07-17T07:16:51.312355Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate peak absolute magnitude\n",
    "xmatched_alerts_real['peak_abs_mag'] = ### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T07:16:52.250560Z",
     "start_time": "2025-07-17T07:16:52.239782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out alerts with absolute magnitudes brighter than -16\n",
    "subluminous_alerts = ## Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:23:36.996341Z",
     "start_time": "2025-07-27T23:23:36.966230Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"After filtering out sources with peak_abs_mag > -16, we have {len(subluminous_alerts)} alerts left.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:41:10.381508Z",
     "start_time": "2025-07-27T23:41:10.376150Z"
    }
   },
   "outputs": [],
   "source": [
    "# We have reduced the list from 450k to 4! Let us plot these sources to vet them and see which ones are further interesting.\n",
    "for ind in tqdm(range(len(subluminous_alerts))):\n",
    "    _ = get_lc_data(\n",
    "        subluminous_alerts.iloc[ind]['oid'],\n",
    "        alerce,\n",
    "        doLC=True,\n",
    "        doStamps=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that Luminous Red Novae show a double peaked lightcurve that has a blue first peak followed by a second red peak. Do any of these transients follow this description?\n",
    "\n",
    "We have successfully recovered the Luminous Red Nova ZTF21aagppzg / AT2021blu!!\n",
    "\n",
    "There are still some contaminants despite all our filtering. How can you get rid of them?\n",
    "- A few artifacts appear to be nuclear sources. These could be AGN. Xmatching to AGN catalogs would help here\n",
    "- Some transients appear to be extremely long-lived. Some have unrealistic photometric scatter.\n",
    "- Some transients remain blue throughout, unlike LRNe.\n",
    "\n",
    "Note that these filtering steps that allowed us to identify this LRN all dealt with photometric data, without requiring any spectroscopic observations! Galaxy catalogs thus provide a powerful tool to search for low luminosity transients in Rubin data. LRNe are special cases as they show a characteristic lightcurve shape, so in principle they can be identified without any spectroscopic observations.\n",
    "\n",
    "### Breakout 2 -\n",
    "- Discuss what challenges you could face while doing this. Will the LSST cadence be an issue? What will be the major contaminants in this search?\n",
    "- The ZTF discovery rate of LRNe is ~2-3 every year. What would the LRN discovery rate be with Rubin?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The diversity of low luminosity transients\n",
    "\n",
    "We have seen how to identify a LRN in ZTF data. However, there are many other low luminosity transients that can be identified in a similar way. Let us look at the lightcurves of a few more classes of low luminosity transients, and see how they differ from LRNe.\n",
    "\n",
    "Problem 3a : Look at the lightcurves of following transients in ZTF data:\n",
    "- ZTF21aagppzg : LRN\n",
    "- ZTF23aajlkxc : LRN\n",
    "- ZTF19aadyppr : ILRT\n",
    "- ZTF19acoaiub : ILRT\n",
    "- ZTF21aagydmn : Possible LBV outburst\n",
    "- ZTF21aaoryiz : Low luminosity Type Iax supernova\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:24:27.040704Z",
     "start_time": "2025-07-27T23:24:27.032488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make lightcurve plots for the above sources\n",
    "alerce = Alerce()\n",
    "for name in ['ZTF21aagppzg', 'ZTF23aajlkxc', 'ZTF19aadyppr', 'ZTF19acoaiub', 'ZTF21aagydmn', 'ZTF21aaoryiz']:\n",
    "    ## Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differences do you see in these lightcurves?\n",
    "\n",
    "- LRNe have a characteristic double peaked lightcurve, with a blue first peak followed by a red second peak.\n",
    "- ILRTs have a single peaked lightcurve that is generally redder than LRNe.\n",
    "- LBVs tend to be blue, however the dustiest LBV outbursts can also be red. In general, LBVs have multiple outbursts, so archival data from other surveys can be used to flag a candidate as a possible LBV.\n",
    "- Low luminosity thermonuclear transients like SNe Iax tend to fade fast.\n",
    "\n",
    "In my experience, of the different classes of low luminosity transients, LRNe are the easiest ones to identify photometrically. The other ones are .. less easy .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Precursor emission\n",
    "A benefit of focusing on nearby transients is that they allow searching for eruption preceding and after the main outburst. Let us look at an example to illustrate this.\n",
    "\n",
    "Problem 4a : Examine the lightcurve of the Luminous Red Nova ZTF19adakuot. This source erupted in M31, (distance modulus of 24.5). ZTF missed majority of the main eruption due to visibility constraints, but the field was observed right up to a few days after the eruption. Plot the ZTF lightcurve of this transient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:25:16.817209Z",
     "start_time": "2025-07-27T23:25:16.771365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the lightcurve for ZTF19adakuot\n",
    "alerce = Alerce()\n",
    "\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the main eruption (absolute magnitude ~ -9) that starts off as blue and transitions rapidly to red colors. There are several detections preceding this! These precursor brightenings are believed to originate in outflows from the common-envelope prior to the merger, and thus they can tell us a lot about the common-envelope phase. However, such precursor detections are extremely rare! In fact, ZTF19adakuot is the only extragalactic LRN that has multiband precursor emission.\n",
    "\n",
    "Problem 4b : What is the detection horizon limit for LRN precursor emission for a survey like ZTF? How does this compare to LSST? (Assume the precursors have similar luminosities as that for ZTF19adakuot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:25:34.748813Z",
     "start_time": "2025-07-27T23:25:34.741050Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "print(f\"Detection horizon distance for precursor emission with ZTF: {ztf_dists:.2f}\")\n",
    "print(f\"Detection horizon distance for precursor emission with LSST: {lsst_dists:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Progenitor identifications\n",
    "\n",
    "Another advantage of focusing on transients in nearby galaxies is they offer the possibility of looking at archival pre-eruption imaging to identify the progenitor system.\n",
    "\n",
    "Let's go back to our original source ZTF21aagppzg. Check for pre-eruption images of ZTF21aagppzg. You can check for HST images [here](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html), or the Pan-STARRS images [here](https://ps1images.stsci.edu/cgi-bin/ps1cutouts?pos=&filter=color&filter=g&filter=r&filter=i&filter=z&filter=y&filetypes=stack&auxiliary=data&size=240&output_size=0&verbose=0&autoscale=99.500000&catlist=).\n",
    "\n",
    "From Pastorello et al. 2022, the progenitor magnitudes of ZTF21aagppzg are :\n",
    "M$_{r}=-6.76 \\pm 0.19$, M$_{g}=-6.49 \\pm 0.26$, M$_{i}=-6.87 \\pm 0.28$, M$_{z} = -6.89 \\pm 0.35$\n",
    "\n",
    "Fit a blackbody to the SED of the progenitor star to estimate the temperature and luminosity of the progenitor primary star (assuming that the primary star dominates the flux measurements). Use a distance of $\\approx 10$ Mpc for the host galaxy. You can use the fitting method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:26:50.002503Z",
     "start_time": "2025-07-27T23:26:49.994793Z"
    }
   },
   "outputs": [],
   "source": [
    "abs_mags = np.array([-6.49, -6.76, -6.87, -6.89])\n",
    "abs_maguncs = np.array([0.26, 0.19, 0.28, 0.35])\n",
    "wavs_um = np.array([0.477, 0.621, 0.754, 0.893])  # g, r, i, z in microns\n",
    "D = 10 # Mpc\n",
    "\n",
    "### Compute and plot the SED as fnu in uJy vs wavelength in micron\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:40:34.105067Z",
     "start_time": "2025-07-27T23:40:34.080391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the blackbody to the data using emcee\n",
    "def lnprior(theta):\n",
    "    ## Your code here\n",
    "    pass\n",
    "\n",
    "\n",
    "def lnlike(theta, wavs, fnu, fnu_unc, D=10 *3.086e24):\n",
    "    ## Your code here\n",
    "    pass\n",
    "\n",
    "\n",
    "def lnprob(theta, wavs, fnu, fnu_unc):\n",
    "    if theta[0] > 0:\n",
    "        log_like = lnlike(theta, wavs, fnu, fnu_unc)\n",
    "    else:\n",
    "        log_like = 0\n",
    "    return lnprior(theta) + log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:40:46.405273Z",
     "start_time": "2025-07-27T23:40:46.399685Z"
    }
   },
   "outputs": [],
   "source": [
    "nwalkers = 20\n",
    "ndim = 2\n",
    "initial = np.array([6800, 150*7e10])  # Initial guess for T and R\n",
    "initial = np.random.normal(loc=initial, scale=[50, 50*7e10], size=(nwalkers, ndim))\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(wavs_um, fnu_ujy, fnu_unc))\n",
    "\n",
    "sampler.run_mcmc(initial, 500, progress=True)\n",
    "\n",
    "samples = sampler.get_chain(flat=True, discard=50)\n",
    "\n",
    "fig = corner.corner(samples, labels=['T (K)', 'R (cm)'], quantiles=[0.16, 0.5, 0.84], show_titles=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:22:33.190009Z",
     "start_time": "2025-07-17T08:22:33.176519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated temperature: [5542.11791868 6706.27682007 8315.10928506] K\n",
      "Estimated radius: [ 85.26681234 143.11980413 208.16565332] Rsun\n",
      "Estimated luminosity: [1.35592933e+38 1.57046351e+38 1.82388142e+38]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimated temperature: {np.nanpercentile(samples[:, 0], [16, 50, 84])} K\")\n",
    "print(f\"Estimated radius: {np.nanpercentile(samples[:, 1], [16, 50, 84])/7e10} Rsun\")\n",
    "lums = (4*np.pi* (samples[:, 1])**2 * 5.67e-5 * (samples[:, 0])**4)\n",
    "print(f\"Estimated luminosity: {np.nanpercentile(lums, [16, 50, 84])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the luminosity and temperature on an HR diagram, and compare it to MIST stellar evolutionary tracks (look at the relevant tracks on https://waps.cfa.harvard.edu/MIST/model_grids.html#eeps) and derive constraints on the progenitor primary mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T22:56:55.162649Z",
     "start_time": "2025-07-27T22:56:55.117917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions to read MIST models\n",
    "mist_colnames = ['star_age',\n",
    "'star_mass',\n",
    "'star_mdot',\n",
    "'he_core_mass',\n",
    "'c_core_mass',\n",
    "'o_core_mass',\n",
    "'log_L'      ,\n",
    "'log_L_div_Ledd',\n",
    "'log_LH'        ,\n",
    "'log_LHe'       ,\n",
    "'log_LZ'        ,\n",
    "'log_Teff'      ,\n",
    "'log_abs_Lgrav' ,\n",
    "'log_R'         ,\n",
    "'log_g'         ,\n",
    "'log_surf_z'    ,\n",
    "'surf_avg_omega',\n",
    "'surf_avg_v_rot',\n",
    "'surf_num_c12_div_num_o16',\n",
    "'v_wind_Km_per_s'         ,\n",
    "'surf_avg_omega_crit'   ,\n",
    "'surf_avg_omega_div_omega_crit',\n",
    "'surf_avg_v_crit'       ,\n",
    "'surf_avg_v_div_v_crit' ,\n",
    "'surf_avg_Lrad_div_Ledd',\n",
    "'v_div_csound_surf',\n",
    "'surface_h1'       ,\n",
    "'surface_he3'      ,\n",
    "'surface_he4'      ,\n",
    "'surface_li7'      ,\n",
    "'surface_be9'      ,\n",
    "'surface_b11'      ,\n",
    "'surface_c12'      ,\n",
    "'surface_c13'      ,\n",
    "'surface_n14'      ,\n",
    "'surface_o16'      ,\n",
    "'surface_f19'      ,\n",
    "'surface_ne20'     ,\n",
    "'surface_na23'     ,\n",
    "'surface_mg24'     ,\n",
    "'surface_si28'     ,\n",
    "'surface_s32'      ,\n",
    "'surface_ca40'     ,\n",
    "'surface_ti48'     ,\n",
    "'surface_fe56'     ,\n",
    "'log_center_T'     ,\n",
    "'log_center_Rho'   ,\n",
    "'center_degeneracy',\n",
    "'center_omega'     ,\n",
    "'center_gamma'     ,\n",
    "'mass_conv_core'   ,\n",
    "'center_h1'        ,\n",
    "'center_he4'       ,\n",
    "'center_c12'       ,\n",
    "'center_n14'       ,\n",
    "'center_o16'       ,\n",
    "'center_ne20'      ,\n",
    "'center_mg24'      ,\n",
    "'center_si28'      ,\n",
    "'pp'               ,\n",
    "'cno'              ,\n",
    "'tri_alfa'         ,\n",
    "'burn_c'           ,\n",
    "'burn_n'           ,\n",
    "'burn_o'           ,\n",
    "'c12_c12'          ,\n",
    "'delta_nu'         ,\n",
    "'delta_Pg'         ,\n",
    "'nu_max'           ,\n",
    "'acoustic_cutoff'  ,\n",
    "'max_conv_vel_div_csound',\n",
    "'max_gradT_div_grada'    ,\n",
    "'gradT_excess_alpha'     ,\n",
    "'min_Pgas_div_P'         ,\n",
    "'max_L_rad_div_Ledd'     ,\n",
    "'e_thermal'              ,\n",
    "'phase',]\n",
    "\n",
    "\n",
    "def open_mist_model(filename):\n",
    "    model = ascii.read(filename, names = mist_colnames)\n",
    "    model = model[(model['phase']>=0)  & (model['phase']<=5)]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T22:56:58.269332Z",
     "start_time": "2025-07-27T22:56:55.921284Z"
    }
   },
   "outputs": [],
   "source": [
    "m10 = open_mist_model('files/mist_tracks/01000M.track.eep')\n",
    "m11 = open_mist_model('files/mist_tracks/01100M.track.eep')\n",
    "m12 = open_mist_model('files/mist_tracks/01200M.track.eep')\n",
    "m13 = open_mist_model('files/mist_tracks/01300M.track.eep')\n",
    "m14 = open_mist_model('files/mist_tracks/01400M.track.eep')\n",
    "m15 = open_mist_model('files/mist_tracks/01500M.track.eep')\n",
    "m16 = open_mist_model('files/mist_tracks/01600M.track.eep')\n",
    "m17 = open_mist_model('files/mist_tracks/01700M.track.eep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T23:39:36.434962Z",
     "start_time": "2025-07-27T23:39:36.417740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the MIST tracks on an HR diagram and overplot the LRN progenitor location\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout 3:\n",
    "In the Rubin era, what sources of archival data will be relevant? Review the specifications of the following missions and discuss their efficacy for archival progenitor identifications :\n",
    "- Euclid\n",
    "- HST/JWST\n",
    "- Roman\n",
    "- Rubin itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Problem :\n",
    "For ZTF21aagppzg, compute the luminosity and the duration of the plateau phase, and use it to determine the total ejected mass using the recombination-powered lightcurve model given in [Matsumoto and Metzger 2022](https://arxiv.org/abs/2202.10478). How does the ejected mass compare to the progenitor mass you just derived above?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
