{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43ff972-fc7e-4430-a281-a4a487dc29a1",
   "metadata": {},
   "source": [
    "## Intro to LSST DP1\n",
    "\n",
    "The goal of this notebook is to demonstrate the use of the first data products released from LSST -- the Data Preview 1. These observations were acquired during Nov - Dec 2024 using the LSST Commissioning Camera -- basically using 1 of the 21 CCD mosaics in the full camera, and placed at the center of the field of view. More details about the commissioning camera [here](https://lsstcomcam.lsst.io/index.html).\n",
    "\n",
    "The data were processed through the standard LSST pipeline and the products were publicly made available on June 30, 2025. Although the actual LSST data stream will consistent of alert \"packets\" (similar to ZTF) that can filtered on, the DP1 products allow us to directly query the backend database in SQL-like format and perform very similar operations. \n",
    "\n",
    "The goals of this notebook are to \n",
    "* Provide a visual introduction to LSST Comcam data, and demonstrate the dramatic improvement over exisiting surveys\n",
    "* Show examples of ways to utilize this data for both quasi-variable and transient sources\n",
    "* Simulate a real LSST-like (i.e. slower cadence) time series to visualize what actual LSST data will look like\n",
    "\n",
    "Builds heavily on the candidate transient identification notebooks provided as part of the LSST DP1 tutorials.\n",
    "\n",
    "## Required Modules\n",
    "Since we are running within the RSP, we do not have to worry about installing invidual modules; instead, we will import them directly on the platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f56551-a45e-47f6-9e89-8b64d10f763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import the main modules we'll need for the tutorial\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import Angle\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO, BytesIO\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import ImageNormalize, LinearStretch\n",
    "import numpy as np\n",
    "\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.afw.image import ExposureF\n",
    "from lsst.afw.fits import MemFileManager\n",
    "\n",
    "from lsst.rsp.service import get_siav2_service\n",
    "from lsst.rsp.utils import get_pyvo_auth\n",
    "\n",
    "from pyvo.dal.adhoc import DatalinkResults, SodaQuery\n",
    "import lsst.geom as geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f59909-f808-4256-840a-32e3b1309bb8",
   "metadata": {},
   "source": [
    "## Comparing LSST to its predecessors\n",
    "\n",
    "With its real-time alert stream, the Zwicky Transient Facility (ZTF) presents a fairly good comparison for a precursor LSST dataset, and has been widely used in the community for time domain science. However, ZTF was on a much smaller telescope (but with larger field of view), allowing it to probe somewhat different parameter space in the transient landscape.\n",
    "\n",
    "Naturally a good starting point is to compare ZTF and LSST directly, and see the improvements in making this jump. Although the two are in different hemispheres, a large fraction of the DP1 [Observations](https://dp1.lsst.io/overview/observations.html) happened to be in a part of the sky where both ZTF and LSST have coverage -- the Extended Chandra Deep Field South (ECDFS). This is also the field with the maximum number of observations in DP1, and therefore we will focus on this field to start with this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35590df1-77a6-44ce-9a29-840ab66903ee",
   "metadata": {},
   "source": [
    "Let's begin by just plotting a visual image of the center of ECDFS field as seen by ZTF and LSST. First, we'll pull the archival ZTF single visit images from the [IRSA](https://irsa.ipac.caltech.edu/Missions/ztf.html) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85203f4-9017-4514-9aac-8cc0ea281489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target coordinates (ECDFS)\n",
    "target_ra = 53.1246023\n",
    "target_dec = -27.7404715\n",
    "\n",
    "# Step 1: Query metadata from IRSA\n",
    "metadata_url = (\n",
    "    f\"https://irsa.ipac.caltech.edu/ibe/search/ztf/products/sci\"\n",
    "    f\"?POS={target_ra},{target_dec}\"\n",
    "    \"&SIZE=0.1\"\n",
    "    \"&INTERSECT=OVERLAPS\"\n",
    "    \"&COLUMNS=filefracday,field,filtercode,ccdid,qid,imgtypecode,maglimit\"\n",
    "    \"&ct=csv\"\n",
    ")\n",
    "\n",
    "print(\"Querying IRSA metadata...\")\n",
    "response = requests.get(metadata_url)\n",
    "response.raise_for_status()\n",
    "df = pd.read_csv(StringIO(response.text), comment=\"#\")\n",
    "\n",
    "# Step 2: Select a random r-band (zr) image\n",
    "df_r = df[df[\"filtercode\"] == \"zr\"]\n",
    "if df_r.empty:\n",
    "    raise RuntimeError(\"No r-band images found at this position.\")\n",
    "row = df_r.sample(n=1).iloc[0]\n",
    "\n",
    "# Step 3: Extract metadata\n",
    "filefracday = str(row[\"filefracday\"])\n",
    "field = str(row[\"field\"]).zfill(6)\n",
    "filtercode = row[\"filtercode\"]\n",
    "ccdid = f\"{int(row['ccdid']):02d}\"\n",
    "qid = f\"{int(row['qid'])}\"\n",
    "imgtypecode = row[\"imgtypecode\"]\n",
    "year, month, day = filefracday[:4], filefracday[4:6], filefracday[6:8]\n",
    "fracday = filefracday[8:]\n",
    "\n",
    "filename = f\"ztf_{filefracday}_{field}_{filtercode}_c{ccdid}_{imgtypecode}_q{qid}_sciimg.fits\"\n",
    "cutout_url = (\n",
    "    f\"https://irsa.ipac.caltech.edu/ibe/data/ztf/products/sci/\"\n",
    "    f\"{year}/{month}{day}/{fracday}/{filename}\"\n",
    "    f\"?center={target_ra},{target_dec}&size=216arcsec&gzip=false\"\n",
    ")\n",
    "\n",
    "print(f\"Fetching cutout from:\\n{cutout_url}\")\n",
    "cutout_response = requests.get(cutout_url)\n",
    "cutout_response.raise_for_status()\n",
    "\n",
    "# Step 4: Display FITS cutout\n",
    "hdul = fits.open(BytesIO(cutout_response.content))\n",
    "image_data = hdul[0].data\n",
    "image_data -= np.median(image_data)\n",
    "\n",
    "vmin = np.percentile(image_data, 10)\n",
    "vmax = np.percentile(image_data, 90)\n",
    "norm = ImageNormalize(image_data, vmin=vmin, vmax=vmax, stretch=LinearStretch(), clip=True)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_data, origin=\"lower\", cmap=\"gray\", norm=norm)\n",
    "plt.title(\"Typical r-band ZTF Cutout at ECDFS\")\n",
    "plt.colorbar(label=\"Pixel value\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f6169-f789-4b77-af1e-fd1afeb7efd2",
   "metadata": {},
   "source": [
    "And there we see a nice image of a few faint galaxies right at the center of the field. Recall that the typical depth of ZTF is about r ~ 20.5 mag with a pixel scale of 1\"/pixel, and most of these objects (even visually) appear close to the detection threshold. Comparatively, LSST single band visits are projected to be ~4 mags (40X) deeper with pixels that are 5 times finer (0.2\"/pixel; or 25X smaller area per pixel). \n",
    "\n",
    "Let's see how than pans out in real data by directly pulling data from DP1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f21e4-cf0c-4591-91c3-7fa7496368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display backend\n",
    "afwDisplay.setDefaultBackend(\"matplotlib\")\n",
    "\n",
    "# Define ECDFS cutout parameters\n",
    "target_ra = 53.1246023\n",
    "target_dec = -27.7404715\n",
    "eff_wl = 622.1e-09  # meters\n",
    "time1 = Time(60600.256, format=\"mjd\", scale=\"tai\")\n",
    "time2 = Time(60700.259, format=\"mjd\", scale=\"tai\")\n",
    "search_radius = 0.01  # degrees\n",
    "\n",
    "# Connect to DP1 SIA service\n",
    "service = get_siav2_service(\"dp1\")\n",
    "assert service is not None\n",
    "\n",
    "# SIA query for visit image\n",
    "circle = (target_ra, target_dec, search_radius)\n",
    "results = service.search(pos=circle, calib_level=2, dpsubtype='lsst.visit_image',\n",
    "                         band=eff_wl, time=(time1, time2))\n",
    "assert len(results) > 0, \"No visit image found.\"\n",
    "\n",
    "# Get datalink and build SODA query\n",
    "datalink_url = results[3].access_url\n",
    "dl_result = DatalinkResults.from_result_url(datalink_url, session=get_pyvo_auth())\n",
    "soda = SodaQuery.from_resource(dl_result,\n",
    "                               dl_result.get_adhocservice_by_id(\"cutout-sync\"),\n",
    "                               session=get_pyvo_auth())\n",
    "\n",
    "# Define cutout center and radius\n",
    "spherePoint = geom.SpherePoint(target_ra * geom.degrees, target_dec * geom.degrees)\n",
    "cutout_radius = 0.03* u.deg #108 arcsec\n",
    "\n",
    "soda.circle = (spherePoint.getRa().asDegrees() * u.deg,\n",
    "               spherePoint.getDec().asDegrees() * u.deg,\n",
    "               cutout_radius)\n",
    "\n",
    "# Execute the cutout request and load into ExposureF\n",
    "cutout_bytes = soda.execute_stream().read()\n",
    "soda.raise_if_error()\n",
    "mem = MemFileManager(len(cutout_bytes))\n",
    "mem.setData(cutout_bytes, len(cutout_bytes))\n",
    "exposure = ExposureF(mem)\n",
    "\n",
    "image_array = exposure.image.array\n",
    "vmin = np.percentile(image_array, 10)\n",
    "vmax = np.percentile(image_array, 90)\n",
    "\n",
    "display = afwDisplay.Display()\n",
    "display.scale('linear', vmin, vmax)\n",
    "display.mtv(exposure)\n",
    "\n",
    "display.image(exposure.image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f006573-a3cf-429c-8232-3fb289f574c8",
   "metadata": {},
   "source": [
    "Dang! As you can see, LSST provides superior depth and spatial resolution compared to ZTF. What we've shown here is a single band, single visit LSST image cutout -- however, real LSST users will (mostly) not need to use the images directly but instead rely on the data products derived from these images (source positions, brightnesses etc). With this brief demonstration of the increased depth, we are ready to start exploring the data products directly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf4d3b-7c52-4536-9ff2-51750c6c541d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T02:03:43.341130Z",
     "iopub.status.busy": "2025-07-11T02:03:43.340594Z",
     "iopub.status.idle": "2025-07-11T02:03:43.349373Z",
     "shell.execute_reply": "2025-07-11T02:03:43.348903Z",
     "shell.execute_reply.started": "2025-07-11T02:03:43.341109Z"
    }
   },
   "source": [
    "## Understanding the DP1 data products\n",
    "\n",
    "DP1 provides both a catalog of time-resolved source positions, brightnesses derived from the science images (i.e. images like the one above) and the same derived from difference imaging (i.e. taking the above image and subtracting a template image in the same filter taken some time before). For this exercise, we are going to focus just on the products from difference imaging; further details on all the data products can be found [here](https://dp1.lsst.io/products/index.html). For the difference imaging analysis (DIA), we have to primarily focus on two types of product -- the DIAObjects and the DIASources. \n",
    "\n",
    "\n",
    "As detailed in the release description, a A “DIA source” is a signal-to-noise ratio > 5 detection in a difference image, containing measurements on a difference image at the coordinates of every source detected in that difference image. A “DIA object” is an astrophysical transient or variable object at a static sky coordinate, created by associating DIA sources within a 1 arcsecond radius. Therefore, there can be multiple DIASources associated to the same DIAObject (which is fixed in sky coordinate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a190e-52e7-42ef-8702-eefaf4c70828",
   "metadata": {},
   "source": [
    "Let's begin exploring this with the dataset itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc16b2-b382-41c3-a745-095fd724bf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T22:55:45.584923Z",
     "iopub.status.busy": "2025-07-16T22:55:45.584165Z",
     "iopub.status.idle": "2025-07-16T22:55:45.588270Z",
     "shell.execute_reply": "2025-07-16T22:55:45.587699Z",
     "shell.execute_reply.started": "2025-07-16T22:55:45.584889Z"
    }
   },
   "source": [
    "### Define parameters and functions\n",
    "Create an instance of the TAP service, and assert that it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cedf88-9538-4cf6-96d4-d47885d4f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "\n",
    "from lsst.rsp import get_tap_service\n",
    "from lsst.utils.plotting import (get_multiband_plot_colors,\n",
    "                                 get_multiband_plot_symbols)\n",
    "\n",
    "from pyvo.dal.adhoc import DatalinkResults, SodaQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ec31f-2754-4f23-a4fc-00bbab16dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = get_tap_service(\"tap\")\n",
    "assert service is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aed548-a3e9-4e68-a975-e0b4b8f87bf1",
   "metadata": {},
   "source": [
    "Define filter names, plot markers, linestyles, and colors for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec379f-ae6b-4256-9414-4f7e3d3a7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_names = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "filter_colors = {'u':'b', 'g':'g', 'r':'r', 'i':'y', 'z':'darkorange', 'y':'m'}\n",
    "filter_symbols = {'u':'o', 'g':'o', 'r':'o', 'i':'o', 'z':'o', 'y':'o'}\n",
    "print(filter_colors, filter_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18465c-380e-4a4c-869e-9462cb38ff04",
   "metadata": {},
   "source": [
    "### Get a sample of DiaObjects\n",
    "\n",
    "Define the coordinates (RA and Dec) of the center of the Extended Chandra Deep Field-South field (ECDFS), which is the best-observed field in DP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081114a-9eba-43cd-ac5a-a2a29888002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the central coordinates of the ECDFS field\n",
    "ra = ??\n",
    "dec = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfcbf5-ae60-4e7d-9c5b-7935373b1fcf",
   "metadata": {},
   "source": [
    "Define the TAP query for a 2-degree cone search of the ECDFS for transient candidates in the `DiaObject` table, which contains useful light curve statistics. Of the six bands, the ECDFS field was covered most by the *r*-band (See Table 3 of RTN-011). The candidate search will therefore utilize *r*-band light curve properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147bf2f-9f73-4138-a124-fe436c83c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT ra, dec, diaObjectId, \"\\\n",
    "        \"nDiaSources, r_scienceFluxMean, g_scienceFluxMean, \"\\\n",
    "        \"r_psfFluxNdata, g_psfFluxNdata \"\\\n",
    "        \"FROM dp1.DiaObject \"\\\n",
    "        \"WHERE CONTAINS (POINT('ICRS', ra, dec), \"\\\n",
    "        \"CIRCLE('ICRS',\" + str(ra) + \", \"\\\n",
    "        + str(dec) + \", 2)) = 1 \"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294fdd0-cba2-4f32-a78a-09cc6803ac20",
   "metadata": {},
   "source": [
    "Run the TAP search and fetch the results in table form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1492690-72f7-4d44-ac06-3e77fc1163e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = service.submit_job(query)\n",
    "job.run()\n",
    "job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "print('Job phase is', job.phase)\n",
    "if job.phase == 'ERROR':\n",
    "    job.raise_if_error()\n",
    "assert job.phase == 'COMPLETED'\n",
    "DiaObjsFull = job.fetch_result().to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d9173-0c1f-40a6-a5b7-3967381478dc",
   "metadata": {},
   "source": [
    "### Review DiaObject characteristics\n",
    "\n",
    "Plot the histogram distribution of DiaSources per DiaObject (i.e., the total number of $\\geq5\\sigma$ detections in difference images per DiaObject; at left), and the distribution of the number of `r`-band detections per DiaObject (at right).\n",
    "\n",
    "Notice how the distribution is peaked at small numbers of DiaSources (and `r`-band detections) -- these are either artifacts from single difference images or time-variable sources that were only detected in a few difference images, and are most likely to have a faint time-variable flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de6060-fafd-4d26-a944-feedd8759cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3), sharey=False, sharex=False)\n",
    "\n",
    "ax[0].hist(DiaObjsFull['nDiaSources'], bins=50, log=True, color='gray')\n",
    "ax[0].set_xlabel('nDiaSources')\n",
    "ax[0].set_ylabel('Counts of DiaObjects')\n",
    "\n",
    "ax[1].hist(DiaObjsFull['r_psfFluxNdata'], bins=50, log=True, color=filter_colors['r'])\n",
    "ax[1].set_xlabel('r_psfFluxNdata')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Total number of unique variable/transient sources', len(DiaObjsFull))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21f87f-f964-4fb3-8caf-411e24351fc6",
   "metadata": {},
   "source": [
    "Remember that the distribution represents only the \"detections\" in the difference images; if a source was constant or the variability (with respect to the template image) was statisically insignificant, those observations would not show up on these histograms even if the source was visually present in the un-subtracted images. Regardless, we see that there are > 200K variable sources even within this tiny < 0.5 sq deg. footprint of the Comcam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30dec4-1656-4aac-bb82-3513f847efa7",
   "metadata": {},
   "source": [
    "In order to see a set of bonafide variables, we'll first apply some simple cuts on the full objects table to reduce it to objects that are consistently detected in multiple epochs. We'll apply the following criteria\n",
    "\n",
    "Filter the full DiaObject results (defined as `DiaObjsFull`) with the following conditions:\n",
    "* `r_scienceFluxMean` < $10^{5.5}$ nJy & `g_scienceFluxMean` < $10^{5.5}$ nJy: Candidate exhibits fluxes sufficiently below saturation limits\n",
    "* `r_psfFluxNdata` > 2 & `g_psfFluxNdata` > 2: Candidate has more than 2 *r*-band detections and more than 2 *g*-band detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98ae27-2be4-4207-bb1f-bcdde7896b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiaObjs = DiaObjsFull[(DiaObjsFull['r_scienceFluxMean'] < ??) & (DiaObjsFull['g_scienceFluxMean'] < ??)]\n",
    "DiaObjs = DiaObjs[(DiaObjs['r_psfFluxNdata'] > ??) & (DiaObjs['g_psfFluxNdata'] > ??)]\n",
    "\n",
    "print(str(len(DiaObjs))+' consistently detected sources.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bb1c8-42a2-441a-946e-605eb26df89e",
   "metadata": {},
   "source": [
    "As we can see, even with that simple cut of requiring multiple detections, we've substantially reduced the number of consistently detected sources. Let's go ahead and look at the contents of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a9d98-3ad0-4cba-8ab5-26d876e371d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print DiaObj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bbbec-9d0e-47e3-bab9-a429c29c517d",
   "metadata": {},
   "source": [
    "For this cleaner subset, we are interested in what their long-term variability looks like; however the DIASource measurments **exist only** when the sources have statistically significant difference fluxes. Therefore, we will instead use the DIA forced photometry measurements stored in the ForcedSourceOnDiaObject object. This table contains forced photometry measurements on *every* DIAObject in the table and on *every* difference image that was recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc475879-a44f-48e6-9859-1872615d82a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cand_list = \"(\" + \", \".join(str(value) for value in DiaObjs['diaObjectId']) + \")\"\n",
    "\n",
    "query = \"SELECT fsodo.coord_ra, fsodo.coord_dec, \"\\\n",
    "        \"fsodo.diaObjectId, fsodo.visit, fsodo.band, \"\\\n",
    "        \"fsodo.psfDiffFlux, fsodo.psfDiffFluxErr, \"\\\n",
    "        \"vis.expMidptMJD \"\\\n",
    "        \"FROM dp1.ForcedSourceOnDiaObject as fsodo \"\\\n",
    "        \"JOIN dp1.Visit as vis ON vis.visit = fsodo.visit \"\\\n",
    "        \"WHERE diaObjectId IN {}\" \\\n",
    "        \"ORDER BY diaObjectId ASC\".format(cand_list)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e759f-613f-4fcb-b682-c580e165778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = service.submit_job(query)\n",
    "job.run()\n",
    "job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "print('Job phase is', job.phase)\n",
    "if job.phase == 'ERROR':\n",
    "    job.raise_if_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd6da2-069d-4729-868c-32efb9611f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert job.phase == 'COMPLETED'\n",
    "FrcdSrc = job.fetch_result().to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c55bd-ef5d-45d5-b317-2bd89cb994ac",
   "metadata": {},
   "source": [
    "## Detecting variability in known variables\n",
    "\n",
    "Given the large size of the number of variable sources, a natural starting point is to ask -- what does a typical variable source look like? As we commonly hear amongst transient astronomers -- *AGN are the vermin of the variable sky* and we can start by examining the light curves of known AGN in this footprint! We'll crossmatch out list of DIAObjects with the [Milliquas](https://ui.adsabs.harvard.edu/abs/arXiv:2308.01505) catalog on Vizier and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b76749-c009-4493-8364-a14bfc0e5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.vizier import Vizier\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61218f2-89c4-4f32-ad40-012df1fed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "Vizier.ROW_LIMIT = -1\n",
    "search_radius = 2 * u.arcsec\n",
    "\n",
    "# Create a SkyCoord for your DiaObjs\n",
    "dia_coords = ??\n",
    "\n",
    "# Query Milliquas for all positions\n",
    "result = Vizier.query_region(dia_coords, radius=search_radius, catalog='VII/294')\n",
    "\n",
    "if len(result) == 0:\n",
    "    print(\"No matches found in Milliquas.\")\n",
    "    matched_table = Table()\n",
    "else:\n",
    "    milliquas = result[0]\n",
    "\n",
    "    # SkyCoord for Milliquas results\n",
    "    mq_coords = SkyCoord(ra=milliquas['RAJ2000'], dec=milliquas['DEJ2000'], unit='deg')\n",
    "\n",
    "    # Match Milliquas sources to nearest LSST DIAObject\n",
    "    idx, sep2d, _ = mq_coords.match_to_catalog_sky(dia_coords)\n",
    "\n",
    "    # Keep only good matches\n",
    "    matched_mq = milliquas\n",
    "    matched_dia = DiaObjs[idx]\n",
    "\n",
    "    # Combine both tables\n",
    "    matched_table = hstack([matched_dia, matched_mq])\n",
    "\n",
    "    print(f\"Matched {len(matched_table)} DIAObjects to Milliquas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6fc5f-67d6-47d6-806d-a5c45c1558d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the contents of the matched table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d74469-d334-4f5d-89ae-37028d7eeaac",
   "metadata": {},
   "source": [
    "Not surprisingly, we see that there are multiple AGN in the Milliquas catalog that were detected as variables in this footprint! We can now proceed with plotting their light curves. Remember that fluxes in difference images are recorded in flux units, and may be positive or negative. In order for easier viewing, we convert the fluxes (originally in nJy) to AB magnitude units, deal with upper limits (i.e. no statistical evidence for positive flux) and plot them all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0916b9-c5d6-4f8f-a57c-92a615abe20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag(flux_njy):\n",
    "    return 31.4 - 2.5 * np.log10(flux_njy)\n",
    "\n",
    "if len(result) > 0:\n",
    "    matched_ids = np.unique(matched_table['diaObjectId'])\n",
    "    n_objs = len(matched_ids)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(n_objs / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 3 * nrows), sharex=False, sharey=False)\n",
    "    axes = axes.reshape(-1)\n",
    "\n",
    "    for idx in range(n_objs):\n",
    "        ax = axes[idx]\n",
    "        dia_id = matched_ids[idx]\n",
    "        lc = FrcdSrc[FrcdSrc['diaObjectId'] == dia_id]\n",
    "\n",
    "        # RA/Dec for title\n",
    "        ra = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['ra'][0]\n",
    "        dec = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['dec'][0]\n",
    "        # Get Milliquas name from match table\n",
    "        name = matched_table[matched_table['diaObjectId'] == dia_id]['Name'][0]\n",
    "        ax.set_title(f\"{name}\\nRA={ra:.5f}, Dec={dec:.5f}\")\n",
    "\n",
    "        # Track brightest detection\n",
    "        brightest_mag = np.inf\n",
    "        brightest_mjd = None\n",
    "        brightest_filt = None\n",
    "\n",
    "        for filt in filter_names:\n",
    "            band_lc = lc[lc['band'] == filt]\n",
    "            good = (\n",
    "                np.isfinite(band_lc['psfDiffFlux']) &\n",
    "                np.isfinite(band_lc['psfDiffFluxErr']) &\n",
    "                (band_lc['psfDiffFluxErr'] > 0)\n",
    "            )\n",
    "            band_lc = band_lc[good]\n",
    "            if len(band_lc) == 0:\n",
    "                continue\n",
    "\n",
    "            flux = band_lc['psfDiffFlux']\n",
    "            flux_err = band_lc['psfDiffFluxErr']\n",
    "            mjd = band_lc['expMidptMJD']\n",
    "\n",
    "            snr = flux / flux_err\n",
    "            detections = (snr >= 5) & (flux > 0)\n",
    "            upper_limits = ~detections\n",
    "\n",
    "            if np.any(detections):\n",
    "                mags = flux_to_mag(flux[detections])\n",
    "                mag_err = 2.5 / np.log(10) * (flux_err[detections] / flux[detections])\n",
    "                mjds = mjd[detections]\n",
    "                ax.errorbar(mjds, mags, yerr=mag_err,\n",
    "                            fmt=filter_symbols[filt],\n",
    "                            color=filter_colors[filt], ms=8, alpha=0.7)\n",
    "\n",
    "                # Brightest point\n",
    "                min_idx = np.argmin(mags)\n",
    "                if mags[min_idx] < brightest_mag:\n",
    "                    brightest_mag = mags[min_idx]\n",
    "                    brightest_mjd = mjds[min_idx]\n",
    "                    brightest_filt = filt\n",
    "\n",
    "            if np.any(upper_limits):\n",
    "                flux_ul = 5 * flux_err[upper_limits]\n",
    "                mags_ul = flux_to_mag(flux_ul)\n",
    "                ax.plot(mjd[upper_limits], mags_ul,\n",
    "                        marker='v', linestyle='None',\n",
    "                        color=filter_colors[filt], alpha=0.5, ms=6)\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_ylabel(\"AB mag\")\n",
    "        if idx >= (nrows - 1) * ncols:\n",
    "            ax.set_xlabel(\"MJD\")\n",
    "\n",
    "        if brightest_mjd is not None:\n",
    "            print(f\"DIAObject {dia_id} — Brightest detection: MJD={brightest_mjd:.2f}, band={brightest_filt}, mag={brightest_mag:.2f}\")\n",
    "\n",
    "    # Remove unused axes\n",
    "    for i in range(n_objs, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af907f6a-d600-47ee-a0bb-1771801bca6b",
   "metadata": {},
   "source": [
    "Nice looking light curves, does anyone stand out? What is the source 3D-HST 35266 and CDFS J03324-2741B doing? Some kind of flare? We are already making discoveries in LSST data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9aefcd-da96-476e-9a3f-db99cf1e01c9",
   "metadata": {},
   "source": [
    "It is worth noticing that many of the time series have multiple observations in the same filter in a given night -- because these were commissioing observations, the cadence of the survey was not controlled and we end up getting very high cadence observations which are not necessarily useful. Going ahead, we will write a function that bins all observation fluxes taken within one night and re-plot the light curves for easier visualization. **This is much closer to what a real LSST time-series would look like**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccde442-c3c3-4377-8fdd-8ddb3e811529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_flux_time(mjd, flux, flux_err, bin_width=1.0):\n",
    "    sort_idx = np.argsort(mjd)\n",
    "    mjd = mjd[sort_idx]\n",
    "    flux = flux[sort_idx]\n",
    "    flux_err = flux_err[sort_idx]\n",
    "\n",
    "    binned_mjd, binned_flux, binned_flux_err = [], [], []\n",
    "    i = 0\n",
    "    while i < len(mjd):\n",
    "        start_time = mjd[i]\n",
    "        j = i\n",
    "        while j < len(mjd) and (mjd[j] - start_time) <= bin_width:\n",
    "            j += 1\n",
    "\n",
    "        mjd_bin = mjd[i:j]\n",
    "        flux_bin = flux[i:j]\n",
    "        err_bin = flux_err[i:j]\n",
    "        weights = 1.0 / err_bin**2\n",
    "\n",
    "        weighted_flux = np.sum(weights * flux_bin) / np.sum(weights)\n",
    "        weighted_err = np.sqrt(1.0 / np.sum(weights))\n",
    "        mean_mjd = np.mean(mjd_bin)\n",
    "\n",
    "        binned_mjd.append(mean_mjd)\n",
    "        binned_flux.append(weighted_flux)\n",
    "        binned_flux_err.append(weighted_err)\n",
    "\n",
    "        i = j\n",
    "\n",
    "    return np.array(binned_mjd), np.array(binned_flux), np.array(binned_flux_err)\n",
    "\n",
    "# Plotting binned light curves\n",
    "matched_ids = np.unique(matched_table['diaObjectId'])\n",
    "n_objs = len(matched_ids)\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(n_objs / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 3 * nrows), sharex=False, sharey=False)\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for idx in range(n_objs):\n",
    "    ax = axes[idx]\n",
    "    dia_id = matched_ids[idx]\n",
    "    lc = FrcdSrc[FrcdSrc['diaObjectId'] == dia_id]\n",
    "\n",
    "    ra = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['ra'][0]\n",
    "    dec = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['dec'][0]\n",
    "    name = matched_table[matched_table['diaObjectId'] == dia_id]['Name'][0]\n",
    "    ax.set_title(f\"{name}\\nRA={ra:.5f}, Dec={dec:.5f}\")\n",
    "\n",
    "    brightest_mag = np.inf\n",
    "    brightest_mjd = None\n",
    "    brightest_filt = None\n",
    "\n",
    "    for filt in filter_names:\n",
    "        band_lc = lc[lc['band'] == filt]\n",
    "        good = (\n",
    "            np.isfinite(band_lc['psfDiffFlux']) &\n",
    "            np.isfinite(band_lc['psfDiffFluxErr']) &\n",
    "            (band_lc['psfDiffFluxErr'] > 0)\n",
    "        )\n",
    "        band_lc = band_lc[good]\n",
    "        if len(band_lc) == 0:\n",
    "            continue\n",
    "\n",
    "        mjd = band_lc['expMidptMJD']\n",
    "        flux = band_lc['psfDiffFlux']\n",
    "        flux_err = band_lc['psfDiffFluxErr']\n",
    "\n",
    "        # Bin within 1 day\n",
    "        mjd_bin, flux_bin, flux_err_bin = bin_flux_time(mjd, flux, flux_err, bin_width=1.0)\n",
    "        snr = flux_bin / flux_err_bin\n",
    "        detections = (snr >= 5) & (flux_bin > 0)\n",
    "        upper_limits = ~detections\n",
    "\n",
    "        if np.any(detections):\n",
    "            mags = flux_to_mag(flux_bin[detections])\n",
    "            mag_err = 2.5 / np.log(10) * (flux_err_bin[detections] / flux_bin[detections])\n",
    "            ax.errorbar(mjd_bin[detections], mags, yerr=mag_err,\n",
    "                        fmt=filter_symbols[filt],\n",
    "                        color=filter_colors[filt], ms=8, alpha=0.7)\n",
    "\n",
    "            min_idx = np.argmin(mags)\n",
    "            if mags[min_idx] < brightest_mag:\n",
    "                brightest_mag = mags[min_idx]\n",
    "                brightest_mjd = mjd_bin[detections][min_idx]\n",
    "                brightest_filt = filt\n",
    "\n",
    "        if np.any(upper_limits):\n",
    "            flux_ul = 5 * flux_err_bin[upper_limits]\n",
    "            mags_ul = flux_to_mag(flux_ul)\n",
    "            ax.plot(mjd_bin[upper_limits], mags_ul,\n",
    "                    marker='v', linestyle='None',\n",
    "                    color=filter_colors[filt], alpha=0.5, ms=6)\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylabel(\"AB mag\")\n",
    "    if idx >= (nrows - 1) * ncols:\n",
    "        ax.set_xlabel(\"MJD\")\n",
    "\n",
    "    if brightest_mjd is not None:\n",
    "        print(f\"{name} — Brightest detection: MJD={brightest_mjd:.2f}, band={brightest_filt}, mag={brightest_mag:.2f}\")\n",
    "\n",
    "# Clean up layout\n",
    "for i in range(n_objs, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ef6bc-49c1-42ed-b872-f3584b5f79d3",
   "metadata": {},
   "source": [
    "## Untargeted searches for transients\n",
    "\n",
    "Now that we've become a bit comfortable with querying the LSST data products, we can be a bit more adventurous and go searching for new ones. We see that looking at the single day binned light curves are somewhat easier when it comes to slower extragalactic sources. Although there are cases to look at the individual epochs, for the next exercise we will search these single day binned light curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e05a60-a271-4742-b7c8-9ce52bd91f53",
   "metadata": {},
   "source": [
    "We will first begin with creating 1-day binned light curves for all the sources in the DIAObject table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003c53c0-cf77-4afa-9e37-037793e328b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T23:07:52.757188Z",
     "iopub.status.busy": "2025-08-03T23:07:52.756582Z",
     "iopub.status.idle": "2025-08-03T23:07:52.779365Z",
     "shell.execute_reply": "2025-08-03T23:07:52.778870Z",
     "shell.execute_reply.started": "2025-08-03T23:07:52.757161Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12768c-9c9c-482f-882e-615d59a5372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for results\n",
    "binned_rows = []\n",
    "\n",
    "# Unique diaObjectIds\n",
    "unique_ids = np.unique(FrcdSrc['diaObjectId'])\n",
    "\n",
    "# Loop with progress bar\n",
    "for dia_id in tqdm(unique_ids, desc=\"Binning light curves\"):\n",
    "    obj_lc = FrcdSrc[FrcdSrc['diaObjectId'] == dia_id]\n",
    "    \n",
    "    for band in np.unique(obj_lc['band']):\n",
    "        band_lc = obj_lc[obj_lc['band'] == band]\n",
    "\n",
    "        # Filter valid data\n",
    "        good = (\n",
    "            np.isfinite(band_lc['psfDiffFlux']) &\n",
    "            np.isfinite(band_lc['psfDiffFluxErr']) &\n",
    "            (band_lc['psfDiffFluxErr'] > 0)\n",
    "        )\n",
    "        band_lc = band_lc[good]\n",
    "        if len(band_lc) == 0:\n",
    "            continue\n",
    "\n",
    "        mjd = band_lc['expMidptMJD']\n",
    "        flux = band_lc['psfDiffFlux']\n",
    "        flux_err = band_lc['psfDiffFluxErr']\n",
    "\n",
    "        # Bin\n",
    "        mjd_bin, flux_bin, flux_err_bin = # use bin_flux_time to compute the binned light curve in 1 day bins\n",
    "\n",
    "        # Append results\n",
    "        for mjd_i, flux_i, err_i in zip(mjd_bin, flux_bin, flux_err_bin):\n",
    "            binned_rows.append((dia_id, band, mjd_i, flux_i, err_i))\n",
    "\n",
    "# Create final table\n",
    "binned_table = Table(rows=binned_rows, names=[\"diaObjectId\", \"band\", \"mjd\", \"psfDiffFlux\", \"psfDiffFluxErr\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626a92b-7eb4-4546-8d04-7b7c9ba2cf67",
   "metadata": {},
   "source": [
    "With this set, we can now proceed to applying specific selection criteria to the light curves themselves. In a typical transient survey, we try to look for things exploding in real-time, i.e. explosive transients that were not there before but appeared during the survey. One way to look for these things is to break down this criteria into pieces\n",
    "\n",
    "* To find new things, we want the source to **not** have been detected at least once or twice before the first detection\n",
    "* We want the source to be detected more than once after it is first detected\n",
    "* Once it is detected, it should stay on for some time (to avoid contamination from sporadically varying sources like AGN).\n",
    "\n",
    "With this light curve set, we will now define some functions to find things like these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b92c6-992a-47d2-a380-02b588d5d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_flare_candidates(binned_table):\n",
    "    \"\"\"\n",
    "    Identify flare candidates satisfying:\n",
    "    - At least 2 non-detections before first detection in the trigger band\n",
    "    - At least 2 detections (SNR > 5) in the trigger band\n",
    "    - No SNR > 3 detections in any band before the flare time\n",
    "    - Persistent detection in trigger band after flare\n",
    "    \"\"\"\n",
    "    flare_candidates = []\n",
    "\n",
    "    for dia_id in np.unique(binned_table['diaObjectId']):\n",
    "        lc = binned_table[binned_table['diaObjectId'] == dia_id]\n",
    "        band_names = np.unique(lc['band'])\n",
    "\n",
    "        for band in band_names:\n",
    "            band_lc = lc[lc['band'] == band]\n",
    "            band_lc = band_lc[np.argsort(band_lc['mjd'])]\n",
    "            snr = band_lc['psfDiffFlux'] / band_lc['psfDiffFluxErr']\n",
    "\n",
    "            detect_idx = np.where(snr > 3)[0]\n",
    "            if len(detect_idx) < ??:\n",
    "                continue  # Require at least 2 detections in trigger band\n",
    "\n",
    "            first_detect_idx = detect_idx[0]\n",
    "            first_detect_mjd = band_lc['mjd'][first_detect_idx]\n",
    "\n",
    "            # Require at least 2 non-detections before first detection in this band\n",
    "            num_nondet_before = np.sum(snr[:first_detect_idx] < 5)\n",
    "            if num_nondet_before < ??:\n",
    "                continue\n",
    "\n",
    "            # No detections in ANY band before this time\n",
    "            preflare_all = lc[lc['mjd'] < first_detect_mjd]\n",
    "            if np.any(preflare_all['psfDiffFlux'] / preflare_all['psfDiffFluxErr'] > 5):\n",
    "                continue\n",
    "\n",
    "            # Persistent detection in this band after flare\n",
    "            if np.all(snr[first_detect_idx:] > ??):\n",
    "                flare_candidates.append((dia_id, band))\n",
    "                break  # only need one valid flare band\n",
    "\n",
    "    return flare_candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d5b5e-df7e-4f16-80f9-f9c955415d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function above to find the list of candidates \n",
    "flare_candidates = ??\n",
    "print('Found %d flare candidates'%len(flare_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d4585-a9d4-4082-88ef-06b4738b0f8a",
   "metadata": {},
   "source": [
    "As we see here, applying this criteria remarkably reduces the number of sources to just five! Let's take a look at their light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80522d12-2c23-48bb-a690-a9fa33179b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flare_candidates(binned_table, flare_candidates, DiaObjs=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def flux_to_mag(flux_njy):\n",
    "        return 31.4 - 2.5 * np.log10(flux_njy)\n",
    "\n",
    "    n_objs = len(flare_candidates)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(n_objs / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 3 * nrows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (dia_id, trigger_band) in enumerate(flare_candidates):\n",
    "        ax = axes[idx]\n",
    "        lc = binned_table[binned_table['diaObjectId'] == dia_id]\n",
    "\n",
    "        # Optional RA/Dec in title\n",
    "        if DiaObjs is not None and 'ra' in DiaObjs.colnames and 'dec' in DiaObjs.colnames:\n",
    "            ra = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['ra'][0]\n",
    "            dec = DiaObjs[DiaObjs['diaObjectId'] == dia_id]['dec'][0]\n",
    "            title = f\"DIAObject {dia_id}\\nRA={ra:.5f}, Dec={dec:.5f}, Flare Band={trigger_band}\"\n",
    "        else:\n",
    "            title = f\"DIAObject {dia_id}\\nFlare Band={trigger_band}\"\n",
    "        ax.set_title(title)\n",
    "\n",
    "        for filt in filter_names:\n",
    "            band_lc = lc[lc['band'] == filt]\n",
    "            if len(band_lc) == 0:\n",
    "                continue\n",
    "\n",
    "            mjd = band_lc['mjd']\n",
    "            flux = band_lc['psfDiffFlux']\n",
    "            flux_err = band_lc['psfDiffFluxErr']\n",
    "            snr = flux / flux_err\n",
    "\n",
    "            detections = (snr > 3) & (flux > 0)\n",
    "            upper_limits = ~detections\n",
    "\n",
    "            if np.any(detections):\n",
    "                mags = flux_to_mag(flux[detections])\n",
    "                mag_err = 2.5 / np.log(10) * (flux_err[detections] / flux[detections])\n",
    "                ax.errorbar(mjd[detections], mags, yerr=mag_err,\n",
    "                            fmt=filter_symbols[filt],\n",
    "                            color=filter_colors[filt], label=filt,\n",
    "                            ms=8, alpha=0.7)\n",
    "\n",
    "            if np.any(upper_limits):\n",
    "                flux_ul = 3 * flux_err[upper_limits]\n",
    "                mags_ul = flux_to_mag(flux_ul)\n",
    "                ax.plot(mjd[upper_limits], mags_ul,\n",
    "                        marker='v', linestyle='None',\n",
    "                        color=filter_colors[filt], alpha=0.5, ms=6)\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_ylabel(\"AB mag\")\n",
    "        if idx >= (nrows - 1) * ncols:\n",
    "            ax.set_xlabel(\"MJD\")\n",
    "\n",
    "    for i in range(n_objs, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a405aeb3-cb5c-44be-8160-b7c680d793cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T23:09:40.504038Z",
     "iopub.status.busy": "2025-08-03T23:09:40.503332Z",
     "iopub.status.idle": "2025-08-03T23:09:40.506485Z",
     "shell.execute_reply": "2025-08-03T23:09:40.506022Z",
     "shell.execute_reply.started": "2025-08-03T23:09:40.504012Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the flare candidates using the function above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d7dad-ce3f-41c3-98f3-833c786148d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbec6791-9449-4799-9930-11eb883841a0",
   "metadata": {},
   "source": [
    "Look at those beautiful looking light curves! Clearly some bonafide transients appearing in the dataset.\n",
    "\n",
    "**Exercise: Search public catalogs, are any of these known transients from other surveys?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7196899-e8ba-4594-9e8a-be6a2dab973c",
   "metadata": {},
   "source": [
    "The next step is to examine the image cutouts themselves to confirm that the transients exist. Let's review the brightest detection for the first object in r band to confirm the nature of the transient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6a5be-136d-4515-894b-5c100f20ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.geom as geom\n",
    "from lsst.afw.math import Warper, WarperConfig\n",
    "sia_service = get_siav2_service(\"dp1\")\n",
    "assert sia_service is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d2b943-a7d1-444d-8c79-fd2d28a3c4cf",
   "metadata": {},
   "source": [
    "### Define a function to get cutouts\n",
    "\n",
    "This section uses the SIA service to find images\n",
    "and the image cutout service to create a \"cutout triplet\".\n",
    "Both services are demonstrated in 100-level tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22485830-91ac-4956-a905-2f5431b92fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutout(dl_result, spherePoint, session, fov):\n",
    "    sq = SodaQuery.from_resource(dl_result,\n",
    "                                 dl_result.get_adhocservice_by_id(\"cutout-sync\"),\n",
    "                                 session=session)\n",
    "    sphereRadius = fov * u.deg\n",
    "    sq.circle = (spherePoint.getRa().asDegrees() * u.deg,\n",
    "                 spherePoint.getDec().asDegrees() * u.deg,\n",
    "                 sphereRadius)\n",
    "    cutout_bytes = sq.execute_stream().read()\n",
    "    sq.raise_if_error()\n",
    "    mem = MemFileManager(len(cutout_bytes))\n",
    "    mem.setData(cutout_bytes, len(cutout_bytes))\n",
    "    return ExposureF(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44094b2c-1217-4647-b8f0-7e293fe41470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cutout_candidate(candid):\n",
    "    # Step 1: First flare candidate\n",
    "    flare_dia_id, trigger_band = flare_candidates[candid]\n",
    "    \n",
    "    # Step 2: Get RA, Dec\n",
    "    row = DiaObjs[DiaObjs['diaObjectId'] == flare_dia_id][0]\n",
    "    ra = row['ra']\n",
    "    dec = row['dec']\n",
    "    spherePoint = geom.SpherePoint(ra * geom.degrees, dec * geom.degrees)\n",
    "    circle = (ra, dec, 0.001)\n",
    "\n",
    "\n",
    "    # Step 3: Find brightest detection in the trigger band\n",
    "    lc = binned_table[\n",
    "        (binned_table['diaObjectId'] == flare_dia_id) &\n",
    "        (binned_table['band'] == trigger_band)\n",
    "    ]\n",
    "\n",
    "    snr = lc['psfDiffFlux'] / lc['psfDiffFluxErr']\n",
    "    valid = (snr > 5) & (lc['psfDiffFlux'] > 0)\n",
    "\n",
    "    if not np.any(valid):\n",
    "        print(\"No valid high SNR detections found.\")\n",
    "    else:\n",
    "        brightest_idx = np.argmax(lc['psfDiffFlux'][valid])\n",
    "        brightest_row = lc[valid][brightest_idx]\n",
    "        brightest_mjd = brightest_row['mjd']\n",
    "        print(f\"Brightest detection: MJD={brightest_mjd:.2f}, Flux={brightest_row['psfDiffFlux']:.2f} nJy\")\n",
    "\n",
    "        # Step 4: Find matching science and diff images near that MJD\n",
    "        results_sci = sia_service.search(pos=circle, calib_level=2)\n",
    "        lvl2_table = results_sci.to_table()\n",
    "        scitab = lvl2_table[\n",
    "            (lvl2_table['dataproduct_subtype'] == 'lsst.visit_image') &\n",
    "            (lvl2_table['lsst_band'] == trigger_band)\n",
    "        ]\n",
    "        scitab.sort('t_max')\n",
    "        sci_row = scitab[np.argmin(np.abs(scitab['t_max'] - brightest_mjd))]\n",
    "\n",
    "        results_lvl3 = sia_service.search(pos=circle, calib_level=3)\n",
    "        lvl3_table = results_lvl3.to_table()\n",
    "\n",
    "        reftab = lvl3_table[\n",
    "            (lvl3_table['dataproduct_subtype'] == 'lsst.template_coadd') &\n",
    "            (lvl3_table['lsst_band'] == trigger_band)\n",
    "        ]\n",
    "        difftab = lvl3_table[\n",
    "            (lvl3_table['dataproduct_subtype'] == 'lsst.difference_image') &\n",
    "            (lvl3_table['lsst_band'] == trigger_band)\n",
    "        ]\n",
    "        difftab.sort('t_max')\n",
    "        diff_row = difftab[np.argmin(np.abs(difftab['t_max'] - brightest_mjd))]\n",
    "\n",
    "        # Step 5: Download cutouts\n",
    "        dl_sci = DatalinkResults.from_result_url(sci_row['access_url'], session=get_pyvo_auth())\n",
    "        dl_ref = DatalinkResults.from_result_url(reftab['access_url'][-1], session=get_pyvo_auth())\n",
    "        dl_diff = DatalinkResults.from_result_url(diff_row['access_url'], session=get_pyvo_auth())\n",
    "\n",
    "        fov = 0.003\n",
    "        sci = get_cutout(dl_sci, spherePoint, get_pyvo_auth(), fov)\n",
    "        ref = get_cutout(dl_ref, spherePoint, get_pyvo_auth(), fov)\n",
    "        diff = get_cutout(dl_diff, spherePoint, get_pyvo_auth(), fov)\n",
    "\n",
    "        # Warp template\n",
    "        warper_config = WarperConfig()\n",
    "        warper = Warper.fromConfig(warper_config)\n",
    "        warped_ref = warper.warpExposure(sci.getWcs(), ref, destBBox=sci.getBBox())\n",
    "\n",
    "        # Plot cutouts\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(9, 3))\n",
    "        titles = ['science', 'template', 'difference']\n",
    "        images = [sci.image, warped_ref.image, diff.image]\n",
    "\n",
    "        for i in range(3):\n",
    "            plt.sca(ax[i])\n",
    "            display = afwDisplay.Display(frame=fig)\n",
    "            display.scale('linear', 'zscale')\n",
    "            display.mtv(images[i])\n",
    "            plt.title(titles[i])\n",
    "            ax[i].set_axis_off()\n",
    "\n",
    "        fig.suptitle(f'Brightest flare cutout\\nDiaObject {flare_dia_id}, Band={trigger_band}, MJD={np.round(brightest_mjd, 2)}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a87c28-a259-43ba-94f9-0830e907bbc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T23:10:29.292033Z",
     "iopub.status.busy": "2025-08-03T23:10:29.291300Z",
     "iopub.status.idle": "2025-08-03T23:10:29.294570Z",
     "shell.execute_reply": "2025-08-03T23:10:29.294044Z",
     "shell.execute_reply.started": "2025-08-03T23:10:29.292001Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now run a loop through the candidates to plot all of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ab9a5-71f3-4b97-867a-225491002711",
   "metadata": {},
   "source": [
    "The cutout confirms that we've identified a bonafide extragalactic supernova on a host galaxy! Now spend some time modifying this code to examine all the other sources. Are they all extragalactic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54c662-03bd-46fd-a933-355a0f92a115",
   "metadata": {},
   "source": [
    "## Repeat this exercise on other fields\n",
    "\n",
    "With this basic setup for filtering on transient sources, we will spend the rest of the time applying this (or a similar) selection on two other files\n",
    "\n",
    "* The Euclid Deep Field South \n",
    "* The Low Galactic Latitude field\n",
    "\n",
    "## Bonus exercise \n",
    "### Think about alternative selections -- red transients? fading transients? nuclear transients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c93bb-4ead-4eb6-a27b-845b31dffffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
