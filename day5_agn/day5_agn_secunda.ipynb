{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20ef00d-a852-4921-9fc8-ff7e57a1a2af",
   "metadata": {},
   "source": [
    "Today we will be using mock AGN light curves from Fagin et al. (2025, https://ui.adsabs.harvard.edu/abs/2024arXiv241018423F/abstract) to explore what we can do with Rubin AGN light curves! We will start by loading in the light curves from Fagin et al. (2025) and then adding the Rubin cadence and errors to these light curves so that we can study how the Rubin cadence might impacts our ability to study AGN light curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b4edc-7b02-42de-978d-354a14cd1b39",
   "metadata": {},
   "source": [
    "# Required python packages (pip install)\n",
    "\n",
    "matplotlib, numpy, glob, astropy, pandas, sqlite3, eztao (pip install git+https://github.com/ywx649999311/EzTao.git), scipy, celerite, numba, emcee\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c8681-2b83-4ceb-8320-e39f7fd6e27b",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c0dde-8f3f-4f2c-8b5b-47d92bc57f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some genral packages we will need\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3ceb5-3149-4b03-a286-970d4010ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the mock light curves from Fagin et al. (2025)\n",
    "\n",
    "directory='light_curves'\n",
    "files = sorted(glob.glob(directory+\"/*.fits\"))\n",
    "print(f\"number of saved light curves: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adc530-e9f4-4d4d-a4d8-fc192456ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the light curves\n",
    "bands = list(\"ugrizy\")\n",
    "\n",
    "all_data = []\n",
    "for fname in files:\n",
    "    with fits.open(fname) as hdul:\n",
    "        # Primary = Light curve observed every day at daily intervals\n",
    "        LC_time = []\n",
    "        LC_mag = []\n",
    "        LC_mag_error = []\n",
    "        for band in bands:\n",
    "            LC = hdul[f\"{band.upper()}_BAND\"].data\n",
    "            time = LC[:, 0]\n",
    "            mag = LC[:, 1]\n",
    "            mag_error = LC[:, 2]\n",
    "            LC_time.append(time)\n",
    "            LC_mag.append(mag)\n",
    "            LC_mag_error.append(mag_error)\n",
    "        LC_time = np.stack(LC_time, axis=1)\n",
    "        LC_mag = np.stack(LC_mag, axis=1)\n",
    "        LC_mag_error = np.stack(LC_mag_error, axis=1)\n",
    "        parameters=hdul[0].header\n",
    "\n",
    "    all_data.append({\n",
    "        'LC_time':           LC_time, \n",
    "        'LC_mag':            LC_mag,\n",
    "        'LC_mag_error':      LC_mag_error,\n",
    "        'parameters':       parameters\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aae706-e754-4932-81d2-6f99b77356e6",
   "metadata": {},
   "source": [
    "Let's plot all 6 wavebands of an example light curve quickly to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4f3fd-e198-41f1-ac55-4362fa434a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single row of 6 subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 8), sharex=True, sharey=False)\n",
    "\n",
    "time = all_data[89]['LC_time']\n",
    "mag = all_data[89]['LC_mag']\n",
    "\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.plot(time[:, idx], mag[:, idx],    label='True', linewidth=1.5)\n",
    "    ax.set_ylabel(f'${bands[idx]}$ band mag')\n",
    "    ax.set_xlim(time[:, idx][0],time[:, idx][-1])\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(which='major', direction='in', top=True, right=True, length=7, width=1)\n",
    "    ax.tick_params(which='minor', direction='in', top=True, right=True, length=3, width=1)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.xlabel('Time [days]')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370b93a-8201-4e11-ae66-58acc9169274",
   "metadata": {},
   "source": [
    "Great! Now that we have a light curve we want to add the LSST time sampling and noise. We will need to download the latest simulated Rubin cadence. Please download baseline_v4.3.5_10yrs.db from https://community.lsst.org/t/announcing-new-ocean-ddf-survey-strategy-simulation/10162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15533261-28fb-40c7-afa1-c60c51679682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First read in opsim database, with observing dates, mag errors, and science program\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"baseline_v4.3.5_10yrs.db\")\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "df = pd.read_sql_query('SELECT fieldRA, fieldDec, seeingFwhmEff, observationStartMJD, filter, fiveSigmaDepth, skyBrightness, science_program FROM observations', conn)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ea174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods to add in LSST sampling and noise\n",
    "\n",
    "bandpasses = list(\"ugrizy\")\n",
    "\n",
    "def LSST_photometric_noise(mag,m_5s,band_num):\n",
    "    #https://arxiv.org/pdf/2203.09540.pdf good paper for reference\n",
    "    #They assume sigma_sys = 0.004 mag since its expected sigma_sys < 0.005 mag\n",
    "\n",
    "    gammas = [0.038, 0.039, 0.039, 0.039, 0.039, 0.039]\n",
    "    gamma = gammas[band_num]\n",
    "\n",
    "    x = 10.0 ** (0.4 * (mag - m_5s))\n",
    "    sigma_rand = np.sqrt((0.04 - gamma)*x + gamma*(x**2))\n",
    "\n",
    "    return sigma_rand\n",
    "\n",
    "def get_observed_LC(LC, ddf=False, min_magnitude=13.0, max_magnitude=25.0):\n",
    "    \"\"\"\n",
    "    This function takes in a light curve at a fixed cadence and returns an observed light curve\n",
    "    using LSST sampling and photometric noise.\n",
    "\n",
    "    LC: numpy array, light curve with fixed cadence in units of magnitude\n",
    "    ddf: boolean, True if you want a DDF, False if you want WFD\n",
    "\n",
    "    returns: numpy array, observed light curve, numpy array, photometric noise\n",
    "    \"\"\"\n",
    "\n",
    "    time_list = []\n",
    "    m_5s_list = []\n",
    "\n",
    "\n",
    "    if ddf==True:\n",
    "        field_db=df.where(df['science_program']=='DD').dropna()\n",
    "\n",
    "    if ddf==False:\n",
    "        field_db=df.where(df['science_program']!='DD').dropna()\n",
    "\n",
    "    #pick a random RA/DEC that's in the desired science program and pick \n",
    "    #out all observations within that FOV\n",
    "    dlen=0\n",
    "    while dlen<200:\n",
    "        rint=np.random.randint(len(field_db))\n",
    "        ra=field_db['fieldRA'].values\n",
    "        dec=field_db['fieldDec'].values\n",
    "        new_db = field_db.where((np.abs(field_db['fieldRA'] - ra[rint])<0.75) & \\\n",
    "                (np.abs(field_db['fieldDec'] - dec[rint])<0.75) ).dropna()\n",
    "        times = new_db['observationStartMJD'].dropna().values\n",
    "        filters = new_db['filter'].dropna().values\n",
    "        m_5s = new_db['fiveSigmaDepth'].dropna().values\n",
    "        dlen=len(times)\n",
    "    times-=min(times)\n",
    "\n",
    "    for i,band in enumerate(bandpasses):\n",
    "        idx1 = np.argwhere(filters == band)\n",
    "        time_list.append(np.round(times[idx1]).astype(np.int64))\n",
    "        m_5s_list.append(m_5s[idx1])\n",
    "\n",
    "    utimes = np.zeros(LC.shape)\n",
    "    LC_obs = np.zeros(LC.shape)\n",
    "    stdev = np.zeros(LC.shape)\n",
    "    nutimes=[]\n",
    "    nstdev=[]\n",
    "    nLC_obs=[]\n",
    "    \n",
    "    for i in range(len(bandpasses)):\n",
    "        time = time_list[i]\n",
    "        m_5s = m_5s_list[i]\n",
    "        \n",
    "        sigma_list = []\n",
    "        for j,t in enumerate(time):\n",
    "            mag = LC[t]\n",
    "            sigma = LSST_photometric_noise(mag,m_5s[j],i)\n",
    "            sigma_list.append(sigma)\n",
    "        sigma_list = np.array(sigma_list)\n",
    "\n",
    "        time_unique,index_unique = np.unique(time,return_index=True)\n",
    "        sigma_unique = []\n",
    "        for j in range(len(index_unique)):\n",
    "            if j+1 < len(index_unique):\n",
    "                sigma_list_at_t = sigma_list[index_unique[j]:index_unique[j+1]]\n",
    "            else:\n",
    "                sigma_list_at_t = sigma_list[index_unique[j]:]\n",
    "\n",
    "            # combine the photoemtric noise such that the final noise is lower than the individual noise\n",
    "            new_sigma = 1/np.sqrt(np.sum(1/sigma_list_at_t**2))\n",
    "            sigma_unique.append(new_sigma)\n",
    "\n",
    "        sigma_unique = np.array(sigma_unique)\n",
    "\n",
    "        #adding systematic and rand errors in quadrature to the photometric noise\n",
    "        sigma_sys = 0.005\n",
    "        sigma_unique = np.sqrt(sigma_sys**2 + sigma_unique**2)\n",
    "\n",
    "        # We clip the photometric noise to have a maximum value of 1 mag, can lead to problems if the noise is too large\n",
    "        sigma_unique = np.clip(sigma_unique,None,1.0)\n",
    "\n",
    "        for t, sigma in zip(time_unique,sigma_unique):\n",
    "            # We only include observations that are within the magnitude range of LSST!\n",
    "            random_noise = np.random.normal(0.0, sigma)\n",
    "\n",
    "            # Only include observations that are within the magnitude range of LSST\n",
    "            if min_magnitude <= LC[t,i] + random_noise <= max_magnitude:\n",
    "                utimes[t,i]=t\n",
    "                stdev[t,i] = sigma\n",
    "                LC_obs[t,i] = LC[t,i] + random_noise\n",
    "\n",
    "        #remove unobserved times (zeros), makes it an inhomogenous list\n",
    "        mask = LC_obs[:,i] == 0.0\n",
    "        tutimes=np.delete(utimes[:,i],mask)\n",
    "        nutimes.append(tutimes)\n",
    "        tstdev=np.delete(stdev[:,i],mask)\n",
    "        nstdev.append(tstdev)\n",
    "        tLC_obs=np.delete(LC_obs[:,i],mask)\n",
    "        nLC_obs.append(tLC_obs)    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    return nutimes,nLC_obs, nstdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the methods in the cell above to add LSST sampling and noise to one of the Fagin light curves\n",
    "\n",
    "#select the 90th light curve\n",
    "time = all_data[89]['LC_time']\n",
    "mag = all_data[89]['LC_mag']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LC_times, LC_obs_mean, LC_obs_stdev = get_observed_LC(LC=mag,\n",
    "                                            ddf=True,\n",
    "                                            min_magnitude=-100, \n",
    "                                            max_magnitude=100\n",
    "                                           )\n",
    "\n",
    "# Create a single row of 6 subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 8), sharex=True, sharey=False)\n",
    "\n",
    "\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.plot(time[:, idx], mag[:, idx],    label='true', linewidth=1.5)\n",
    "    ax.errorbar(LC_times[idx], LC_obs_mean[idx], yerr=LC_obs_stdev[idx],  label='obs', fmt='o', markersize=2, elinewidth=1, capsize=2)\n",
    "    ax.set_ylabel(f'${bands[idx]}$ band mag')\n",
    "    #ax.set_xlim(LC_times[0],LC_times[-1])\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(which='major', direction='in', top=True, right=True, length=7, width=1)\n",
    "    ax.tick_params(which='minor', direction='in', top=True, right=True, length=3, width=1)\n",
    "    ax.legend()\n",
    "\n",
    "plt.xlabel('Time [days]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268306cd-9ccb-44cf-94e8-9a78756928d8",
   "metadata": {},
   "source": [
    "# Fit the Light Curve PSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb59092-2da4-4710-8c3b-e94698e8f34e",
   "metadata": {},
   "source": [
    "Great! Now we have mock Rubin AGN light curves. One of the first things we will want to do with Rubin AGN light curves is to study the power specturm of their variability. One particular way we do this is to fit a damped random walk model to the AGN light curve. Because our light curve does not have an even cadence we can not just perform an FFT to look at the power spectrum. Instead we will use a code EzTao that has been specifically designed to fit damped random walk models to AGN light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6a8c5-4c62-4f4b-b890-bc541a9fe53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import eztao and the neccessary modules from eztao\n",
    "import eztao\n",
    "from eztao.ts import drw_fit\n",
    "from eztao.carma import DRW_term\n",
    "from eztao.carma import gp_psd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005013a9-c2eb-4ef4-ac36-3f497dd20068",
   "metadata": {},
   "source": [
    "In the cell below I give an example of how to do this for the full mock g-band light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609625df-4658-4a3f-93ec-40f4f8c60e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the full g-band light curve with a DRW model\n",
    "best_fit_real = drw_fit(time[:,1], mag[:,1],np.zeros(len(mag[:,1])))\n",
    "print(f'Best-fit structure function: {np.round(best_fit_real[0],2)}  Best-fit damping timescale: {np.round(best_fit_real[1])}')\n",
    "\n",
    "# define the true PSD functions using\n",
    "# a new kernel initalized with the best-fit parameters\n",
    "best_fit_kernel_real = DRW_term(*np.log(best_fit_real))\n",
    "true_psd = gp_psd(best_fit_kernel_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3750511-049d-461c-baea-2a1d29f56406",
   "metadata": {},
   "source": [
    "Now try on your own to do this for the mock g-band light curve that has been mock observed by Rubin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3a076-6e1b-4ad2-ba89-987a9d77712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the g-band light curve sub-sampled with the Rubin cadence with a DRW model\n",
    "best_fit = #TODO\n",
    "print(f'Best-fit structure function: {np.round(best_fit[0],2)}  Best-fit damping timescale: {np.round(best_fit[1])}')\n",
    "\n",
    "# define the true PSD functions using\n",
    "# a new kernel initalized with the best-fit parameters\n",
    "best_fit_kernel = #TODO\n",
    "best_psd = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac32c2-b1a7-4a8f-899c-053f1ecf93bc",
   "metadata": {},
   "source": [
    "Let's plot the two PSDs to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a33a7f-0a74-4364-8fb6-73c2e7a9c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "freq = np.logspace(-4, 2)\n",
    "plt.plot(freq,true_psd(freq))\n",
    "plt.plot(freq,best_psd(freq))\n",
    "\n",
    "plt.gca().set_xscale('log')\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10931f1-6098-4ca7-80f4-e641dc0e9705",
   "metadata": {},
   "source": [
    "# Reverberation Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d69c2b-bff7-47a1-809f-a3ce237a1ad6",
   "metadata": {},
   "source": [
    "We will also want to use Rubin AGN light curves to perform reverberation mapping on thousands of AGN. Reverberation mapping measures the lag in variability between different wavebands on the light-crossing timescale to measure the radial extent and radial temperature profile of an AGN disk. The most tried and true way to find the lag in variability between two wavebands is to use the interpolated cross correlation function (Peterson, 2004). To do so we first need to linearly interpolate our mock-observed data back to a daily cadence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0b9a7-16b6-43b0-bb8c-1511a6668a74",
   "metadata": {},
   "source": [
    "In the cell below linearly interpolate the g-band light curve to a daily cadence and plot and compare the interpolated data to the true light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e3c0b-63b7-436e-855b-d06fdac7fa13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "385896a2-7272-4fa0-bb3f-d6f266c8d976",
   "metadata": {},
   "source": [
    "Now linearly interpolate the z-band light curve to a daily cadence and plot and compare the interpolated data to the true light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a57173-fc24-46f7-8b5a-f48a71a580bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dd66a10-3890-4c01-9362-aff7d1d92b2a",
   "metadata": {},
   "source": [
    "In the cell below plot and compare your interpolated u-band and y-band light curve. You may want to normalize each light curve by diving them by their mean magnitudes in order to normalize them for easier comparison.\n",
    "\n",
    "Adjust your x-axis limits to take a closer look at the first 100 days of data. Can you see by eye that the longer wavelength band (the z-band) is lagging the g-band? Can you shift the time of the z-band light curve by subtracting a value from the time to predict by eye what lag you anticipate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d93c85-eec0-4c8c-96db-e86ef56f0f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa86dd90-022d-4f36-932a-98aaded22dfb",
   "metadata": {},
   "source": [
    "Now that we have linearly interpolated the data and made a by eye prediction we will do the cross correlation. You can use scipy.stats.pearsonr to calculate the pearson r-coefficient between the two light curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395974e2-d33c-4b74-8b1b-d2bc5043767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr(imag1,imag4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481760c-ebf0-4dc4-b7ff-9f683f7c1ce4",
   "metadata": {},
   "source": [
    "The Pearson r-coefficient is very strong between the two light curves even if we do not shift them. Now we will want to shift the z-band light curve forward by different one day intervals to try and find the shift that produces the highest r-coefficient. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885f2ea-5825-45ac-801e-5e579d68313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(imag1[:-1],imag4[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b941142-e613-4e2f-9cdf-5f6cddb53bde",
   "metadata": {},
   "source": [
    "The r-coefficient is slightly larger if we shift the z-band light curve forward one day. Play around yourself and see what shift (from 0 to 11 days) gives the largest r-coefficent. Save the r-coefficients in the numpy array rcoeff so that you can plot them in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08e611-f92c-48f8-9563-314409961be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcoeff=np.zeros(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8122128-521e-4894-ad69-703fbf4e3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the R-coefficient as a function of lag\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.plot(np.arange(11),rcoeff)\n",
    "plt.axvline(np.arange(11)[np.argmax(rcoeff)])\n",
    "plt.xlabel('Lag [Days]',fontsize=10)\n",
    "plt.ylabel('R-coefficient',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34baa7f9-d76f-41b0-ac13-78b4b7d02154",
   "metadata": {},
   "source": [
    "That worked pretty well! See if you can play around with:\n",
    "1) Some of the other waveband light curves. How do the lags scale between the g-band and other wavebands? How do DRW parameters change for the same light curve but different wavebands?\n",
    "2) A different light curve by indexing a different light curve to sub-sample with the Rubin cadence. Can EzTao fit a DRW model to all of the mock light curves?\n",
    "3) How well does all of this work for the wide fast deep field? Check by setting ddf=False in the get_observed_lc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49e20e-f47f-48ff-baa7-62aec6025975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fdb70e-0576-4036-b399-fc8812d2bfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dcb33-bce9-423a-976e-55c5e346ae52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f8f3d-85dc-4edf-a32a-7177ec3c0935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82fb9c-9076-4c31-b88e-4e9ddcb8df8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
