{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479795d8",
   "metadata": {},
   "source": [
    "# CCA Summer School: Landscape of Astronomical Transients\n",
    "\n",
    "## Day 1: Introduction to Transient Surveys and Alert Streams\n",
    "\n",
    "### Prepared by Kohki Uno\n",
    "- Research Interests: Supernovae, TDEs, and Weird Transients\n",
    "- Affiliation: Kyoto University -> Columbia University\n",
    "- Email: <k.uno@kusastro.kyoto-u.ac.jp> or <ku2204@columbia.edu>\n",
    "- HP: <https://www.kusastro.kyoto-u.ac.jp/~k.uno/view/index.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9618b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd81f61",
   "metadata": {},
   "source": [
    "# Today's Goals and Summary\n",
    "- Get familiar with the data and technique of transient surveys\n",
    "- Understand the structure of the original ZTF alert\n",
    "- Subscribe to the ZTF data via the ALeRCE broker, reconstruct each object's light curve, and handle the data\n",
    "\n",
    "\n",
    "Three assignments have been prepared for you. Please work through them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c0e9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cfd99",
   "metadata": {},
   "source": [
    "# Step 0: Environment Setup\n",
    "\n",
    "As the first step, I suggest you to create a new python environment (I use Python 3.10):\n",
    "`conda create -n lsstss2025`, and activate the env and install the following python module.\n",
    "\n",
    "## Required Python Packages:\n",
    "install  using `pip` or `conda`\n",
    "- [Astropy](https://www.astropy.org/): Common core package for astronomy\n",
    "- [Numpy](https://numpy.org/): Scientific mathmatical package\n",
    "- [Scipy](https://scipy.org/): Scientific mathmatical package\n",
    "- [Pandas](https://pandas.pydata.org/): Data analysis package\n",
    "- [Matplotlib](https://matplotlib.org/): Visuallization package\n",
    "- [fastavro](https://fastavro.readthedocs.io/en/latest/): for ZTF alert\n",
    "- [alerce.core](https://alerce.readthedocs.io/en/latest/): API for ALeRCe (only for pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from fastavro import reader\n",
    "import gzip, io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from alerce.core import Alerce\n",
    "alerce = Alerce()  # no authentication needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4bb00",
   "metadata": {},
   "source": [
    "Set up the save directory (Although it's included in the GitHub repository, it is defined here just in case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output_day1/'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c83e3",
   "metadata": {},
   "source": [
    "## Ancilliary Datasets:\n",
    "\n",
    "The following materials are already included in the GitHub repository (`LSST_summer_school_2025_Flatiron/day2_ccsne`).\n",
    "If you successfully fork the repository, these files will be downloaded automatically.\n",
    "\n",
    "- `/public_ztf_alert/2765241404615015018.avro`: a single ZTF public alert file\n",
    "- (`alerce_classifiers.json`: a json file for summerizing alerce classifer (not explicitly use in this notebook))\n",
    "\n",
    "In addition, you need to download the following large file from <https://www.dropbox.com/scl/fi/df4ctlq2qgbatejtmca2y/day1_ztf_alert_20240728_min.json?rlkey=dskd8aup6joaycitoj74gmrit&st=hdcvsdad&dl=0>, and put the file in `./output_day2/`.\n",
    "\n",
    "- `day1_ztf_alert_20240728_min.json`: a json file for ZTF alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b55248",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461513d6",
   "metadata": {},
   "source": [
    "# Step 1: Get Familiar with Transient Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd54527",
   "metadata": {},
   "source": [
    "## What is a transient survey?\n",
    "\n",
    "A transient survey is an time-domain observational program designed to discover and monitor astronomical transients that change in brightness or position over short timescales (from seconds to months). \n",
    "\n",
    "These transient phenomena include:\n",
    "- Supernovae (SNe)\n",
    "- Gamma-ray bursts (GRBs)\n",
    "- Tidal disruption events (TDEs)\n",
    "- Variable stars\n",
    "- Active galactic nuclei (AGN)\n",
    "- Moving objects like asteroids  etc...\n",
    "\n",
    "Transient surveys use wide-field (FOV > several square deg) telescopes, and rapid, repeated imaging of the sky to detect these short-timescale events. The goal of the surveys is to detect and characterize such events as immediately and as completely as possible, and connect to detailed follow-up observations.\n",
    "\n",
    "Such surveys have transformed time-domain astronomy, enabling statistical studies of transient rates, real-time alerts, and rapid follow-up with ground- and space-based telescopes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8f2f7",
   "metadata": {},
   "source": [
    "## ZTF: Zwicky Transient Facility\n",
    "\n",
    "[The Zwicky Transient Facility (ZTF)](https://www.ztf.caltech.edu/index.html) is the most powerful time-domain survey using a 48-inch (1.2-meter) Schmidt telescope at the Palomar Observatory. Operational since 2018, ZTF has been scaning the Northern sky every a few nights.\n",
    "\n",
    "Key features of ZTF (see also [Link](https://www.ztf.caltech.edu/ztf-camera.html)):\n",
    "- FOV: 47 square degrees (3750 deg^2 / hour) !\n",
    "- Cadence: $\\sim$ 3 days\n",
    "- Filters: g / r/ i\n",
    "- limiting mag (5-sigma 30sec): 20.8 / 20.6 / 19.9\n",
    "- Targets:\n",
    "    - fast, young, and rare transients\n",
    "    - counterparts to GW sources\n",
    "    - low-z Type Ia SNe for cosmology\n",
    "    - variable stars & eclipsing binaries\n",
    "    - solar system objects    etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df676c4b",
   "metadata": {},
   "source": [
    "## Rubin Observatory / LSST survey\n",
    "[The Vera C. Rubin Observatory](https://rubinobservatory.org/) is a next-generation transient surve using 8.4-meter telescope at Chele. Rubin The will perform 10-year Southern-Hemisphere survey called [the Legacy Survey of Space and Time (LSST)](https://rubinobservatory.org/explore/how-rubin-works/lsst). Revently, it has started operations, and a lot of interesting and suprigin repots will come out! \n",
    "\n",
    "\n",
    "Key features of Rubin/LSST:\n",
    "- 9.6 square degrees field of view\n",
    "- Cadence: $\\sim$ 5 days\n",
    "- Filters: u / g / r / i / z / y\n",
    "- limiting mag (5-sigma 30sec): 23.9 / 25.0 / 24.7 / 24.0 / 23.3 / 21.1\n",
    "- Targets:\n",
    "    - exporing optical transient\n",
    "    - probing dark energy & dark matter\n",
    "    - taking an inventory of the Solar system \n",
    "    - mapping the Milky Way\n",
    "\n",
    "The LSST will generate a data volume of $\\sim$ 20TB per night, producing alerts for ~10 million transient events per night ($\\sim$ 60 PB in 10 years, see also [Link](https://www.lsst.org/about/dm)) — revolutionizing time-domain astronomy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d712798",
   "metadata": {},
   "source": [
    "To prepare for the upcoming LSST era, today’s hands-on exercise will focus on getting you familiar with how to handle data from ZTF alert streams. In addition, we will explore data provided by brokers — community tools that process alert streams from ZTF and from LSST in the future. By working with both raw alerts and broker-enhanced data, you'll gain practical experience with real-world survey data and learn how to efficiently filter, analyze, and interpret transient events.\n",
    "\n",
    "This exercise will provide practical experience with real-world survey data and learn how to efficiently filter, analyze, and interpret transient events, which will also help build foundational skills necessary for scientific discovery in the LSST era."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a976d3e",
   "metadata": {},
   "source": [
    "## Step 1-1: Accessing and handling the public ZTF Alert Stream\n",
    "\n",
    "The environment might has been successfully set up. Now let’s begin the today's hands-on exercise.\n",
    "\n",
    "Public ZTF alerts for each night are available from the following page: <https://ztf.uw.edu/alerts/public/>\n",
    "\n",
    "As you can see, the alert data for a single night typically reaches $\\sim$ 10 GB! Downloading this full dataset even for one night can take a significant amount of time.\n",
    "To save time, a sample data of one alert has already been prepared and stored in: `./output_day1/public_ztf_alert`. This data is alerted on 2024/Jul/28 (just one year ago)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8d6aa",
   "metadata": {},
   "source": [
    "If you are interested in exploring the full ZTF public alert data yourself, you can uncomment the code in the following cell.\n",
    "However, this is optional and intended as homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e02bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the data observed on 2024/July/28 \n",
    "# !wget https://ztf.uw.edu/alerts/public/ztf_public_20240728.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9a3b2",
   "metadata": {},
   "source": [
    "In the directory, you will find an Avro file named `2765241404615015018.avro`.\n",
    "This file represents a single ZTF public alert. A full one-night's alerts typically consists of $>10^{4}$ Avro files.\n",
    "\n",
    "Let’s open this sample Avro file and see what data are stored in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avro_dir = os.path.join(output_dir, 'public_ztf_alert')\n",
    "avro_path = os.path.join(avro_dir, \"2765241404615015018.avro\")\n",
    "\n",
    "with open(avro_path, 'rb') as f:\n",
    "   alert = list(reader(f))\n",
    "   \n",
    "alert = alert[0]\n",
    "print(alert.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe402a",
   "metadata": {},
   "source": [
    "You can see dict data named as.\n",
    "- `schemavsn` – Version number of the alert schema format.\n",
    "- `publisher` – Organization or system that issued the alert (e.g. \"ZTF\").\n",
    "- `objectId` – Unique identifier for the astrophysical object associated with the alert. (i.e., ZTF name)\n",
    "- `candid` – Unique ID for this specific detection (candidate) of the object.\n",
    "- `candidate` – Dictionary containing observational data from this detection (e.g., time, magnitude, RA/Dec).\n",
    "- `prv_candidates` – List of previous detections of the same object, useful for building light curves.\n",
    "- `fp_hists` – Historical false-positive diagnostic information (optional, often unused).\n",
    "- `cutoutScience` – Base64-encoded image stamp of the science observation.\n",
    "- `cutoutTemplate` – Base64-encoded image stamp of the reference template.\n",
    "- `cutoutDifference` – Base64-encoded image stamp of the difference (science - template)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77522bdf",
   "metadata": {},
   "source": [
    "In each ZTF alert, the contentd str stored as dictionary-like style.\n",
    "\n",
    "As one example, let's check data are stored in `candidate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert['candidate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbd28e",
   "metadata": {},
   "source": [
    "The important data in `candidates` are:\n",
    "- `objectId`: A unique identifier for the astronomical source.\n",
    "- `candid`: A unique ID for the specific detection (each alert has one).\n",
    "- `ra`, `dec`: Right ascension and declination of the candidate in degrees (J2000).\n",
    "- `jd`: Julian Date of the observation.\n",
    "- `magpsf`: magnitude of the detection by PSF (Point Spread Function) fitting.\n",
    "- `sigmapsf`: Uncertainty of `magpsf`.\n",
    "- `magap`: magnitude of the detection by apperture photometry.\n",
    "- `sigmagap`: Uncertainty of `magap`.\n",
    "- `fid`: Filter ID (1 = g-band, 2 = r-band, 3 = i-band).\n",
    "- `drb`: Real–Bogus score (machine-learned probability that the source is astrophysical).\n",
    "\n",
    "This is a detection alert in the night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1371a",
   "metadata": {},
   "source": [
    "Furthermore, the Avro file include `cutout` files. These are stamp images of the detections. \n",
    "\n",
    "Let's Vizualize the stamp images!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8495a6",
   "metadata": {},
   "source": [
    "`get_stamp_image(alert, which)`\n",
    "\n",
    "Extract and return a 2D FITS image array (stamp) from a ZTF alert packet.\n",
    "\n",
    "Arguments:\n",
    "- `alert` (dict): A ZTF alert dictionary containing compressed FITS cutout data.\n",
    "- `which` (str): The image type to extract. Must be one of:\n",
    "  - `'Science'`: Science image cutout.\n",
    "  - `'Template'`: Reference image cutout.\n",
    "  - `'Difference'`: Subtracted image cutout.\n",
    "\n",
    "Returns:\n",
    "- `numpy.ndarray`: A 2D image array corresponding to the selected cutout type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2546ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stamp_image(alert, which):\n",
    "\n",
    "    # Extract gzip-compressed image data for the specified cutout type\n",
    "    compressed = alert[\"cutout%s\" % which][\"stampData\"]\n",
    "\n",
    "    # Decompress the data using gzip and load as a FITS HDU\n",
    "    with gzip.open(io.BytesIO(compressed), 'rb') as f:\n",
    "        hdu = fits.open(io.BytesIO(f.read()), ignore_missing_simple=True)[0]\n",
    "\n",
    "        # Return the image data as a 2D NumPy array\n",
    "        return hdu.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7421f1b",
   "metadata": {},
   "source": [
    "`plot_stamp_image(alert)`\n",
    "\n",
    "Visualize the `Science`, `Template`, and `Difference` cutout images from a ZTF alert as a 3-panel plot.\n",
    "\n",
    "Arguments:\n",
    "- `alert` (dict): A ZTF alert dictionary that includes compressed cutout image data for `'Science'`, `'Template'`, and `'Difference'`.\n",
    "\n",
    "Returns:\n",
    "- `None`: Displays a Matplotlib figure with three grayscale image panels. Each panel uses percentile-based scaling (5–99%) to enhance contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stamp_image(alert):\n",
    "\n",
    "    # Retrieve each cutout image as a 2D NumPy array\n",
    "    science_img   = get_stamp_image(alert, 'Science')\n",
    "    template_img  = get_stamp_image(alert, 'Template')\n",
    "    different_img = get_stamp_image(alert, 'Difference')\n",
    "\n",
    "    # Create a 1x3 subplot layout\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    titles = [\"Science\", \"Template\", \"Difference\"]\n",
    "    images = [science_img, template_img, different_img]\n",
    "\n",
    "    # Display each image with percentile scaling for contrast\n",
    "    for ax, img, title in zip(axs, images, titles):\n",
    "        ax.imshow(\n",
    "            img,\n",
    "            cmap='gray',\n",
    "            origin='lower',\n",
    "            vmin=np.percentile(img, 5),\n",
    "            vmax=np.percentile(img, 99)\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')  # Hide axis ticks and labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c6f48",
   "metadata": {},
   "source": [
    "Plot the stamp image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9545c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stamp_image(alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605ee62",
   "metadata": {},
   "source": [
    "`Science` is the observed image at the night, `Template` is the image of the reference, and `Difference` is the subtraction image. You can detect a luminous point at the center of the difference image. This is a transient!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d987855",
   "metadata": {},
   "source": [
    "Then, you might be interested in the time variability of the detected object.\n",
    "ZTF alerts include not only the most recent detection (`candidate`), but also previous detections of the same object. These are stored in `prv_candidates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c17680",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert['prv_candidates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304b231",
   "metadata": {},
   "source": [
    "`prv_candidates` contains previous detection data for the same object.\n",
    "The format of each entry is similar to that of `candidate`, but `prv_candidates` provides a time series of past detections. This time-series information allows us to plot the light curve!!\n",
    "\n",
    "Let’s plot a light curve using this data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564cb63",
   "metadata": {},
   "source": [
    "`plot_ztf_prv_lightcurve(alert)`\n",
    "\n",
    "Plot a light curve using previous candidates from a ZTF alert packet. Both PSF and aperture photometry are displayed for available bands.\n",
    "\n",
    "Arguments:\n",
    "- `alert` (dict): A ZTF alert dictionary containing the `'prv_candidates'` key, which includes privious photometric detections.\n",
    "\n",
    "Returns:\n",
    "- `None`: Displays a Matplotlib light curve plot with error bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ca5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ztf_prv_lightcurve(alert):\n",
    "\n",
    "    detections = alert['prv_candidates']\n",
    "\n",
    "    # Define filter ID to color/label mappings\n",
    "    # fid = 1 (g: green), 2 (r: red), 3 (i: orange)\n",
    "    band_colors = {1: 'green', 2: 'red', 3: 'orange'}\n",
    "    band_labels = {1: 'g-band', 2: 'r-band', 3: 'i-band'}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot detections by band\n",
    "    if len(detections) > 0:\n",
    "        for fid in sorted(set(d['fid'] for d in detections)):\n",
    "            # Filter out entries missing photometry\n",
    "            band_data = [\n",
    "                d for d in detections\n",
    "                if d['fid'] == fid and 'magpsf' in d and 'sigmapsf' in d\n",
    "            ]\n",
    "            if not band_data:\n",
    "                continue\n",
    "\n",
    "            # Extract photometry data\n",
    "            jd = [d['jd'] for d in band_data]\n",
    "            mag = [d['magpsf'] for d in band_data]\n",
    "            err = [d['sigmapsf'] for d in band_data]\n",
    "\n",
    "            # Extract aperture magnitudes if available\n",
    "            mag_ap = [d['magap'] for d in band_data]\n",
    "            err_ap = [d['sigmagap'] for d in band_data]\n",
    "\n",
    "            # PSF photometry (solid markers)\n",
    "            ax.errorbar(\n",
    "                jd, mag, yerr=err,\n",
    "                fmt='o', color=band_colors.get(fid, 'gray'),\n",
    "                label=f'magpsf ({band_labels.get(fid, f\"band {fid}\")})',\n",
    "                markersize=5, linewidth=1\n",
    "            )\n",
    "\n",
    "            # Aperture photometry (semi-transparent)\n",
    "            ax.errorbar(\n",
    "                jd, mag_ap, yerr=err_ap,\n",
    "                fmt='o', color=band_colors.get(fid, 'gray'),\n",
    "                label=f'magap ({band_labels.get(fid, f\"band {fid}\")})',\n",
    "                markersize=5, linewidth=1, alpha=0.3\n",
    "            )\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('JD')\n",
    "    ax.set_ylabel('Magnitude')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a2c57",
   "metadata": {},
   "source": [
    "plot the light curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ztf_prv_lightcurve(alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e092c4a",
   "metadata": {},
   "source": [
    "This is a supernova-like object!!\n",
    "\n",
    "In this way, you can access and handle the ZTF public data if you download the zip file!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75777f7a",
   "metadata": {},
   "source": [
    "## Step 1-2: Summerizing Important Data\n",
    "\n",
    "So far, we have reviewed a single ZTF alert, but the original dataset for one night typically contains $>10^4$ alerts, totaling several GB.\n",
    "\n",
    "TTo make the analysis more efficient and save time, I have preprocessed and extracted key information from all alerts on 2024/Jul/27. Specifically, the following fields have been retained: `objectId`, `candid`, and `candidate`, and the processed dataset is saved as: `./output_day1/day1_ztf_alert_20240728_min.json`.\n",
    "\n",
    "If you would like to try generating this file yourself, you can uncomment the code in the following cell.\n",
    "Note that this step requires the full alert data to be downloaded in Cell [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #10GB ~ 12min\n",
    "# output_path = os.path.join(output_dir, \"ztf_alert_20240728.json\")\n",
    "\n",
    "# alert_dir = './output_day1/ztf_alert_20240728'\n",
    "# with open(output_path, \"w\") as outfile:\n",
    "#     outfile.write(\"[\\n\")\n",
    "\n",
    "#     first = True\n",
    "#     for filename in os.listdir(alert_dir):\n",
    "#         if not filename.endswith(\".avro\"):\n",
    "#             continue\n",
    "\n",
    "#         path = os.path.join(alert_dir, filename)\n",
    "#         with open(path, 'rb') as f:\n",
    "#             for alert in reader(f):\n",
    "#                 # Remove image data and selected metadata\n",
    "#                 for key in ['schemavsn', 'publisher', 'cutoutScience', 'cutoutTemplate', 'cutoutDifference']:\n",
    "#                     alert.pop(key, None)\n",
    "\n",
    "#                 # Output as compact JSON\n",
    "#                 if not first:\n",
    "#                     outfile.write(\",\\n\")\n",
    "#                 json.dump(alert, outfile, separators=(\",\", \":\"))  # ← no spaces, minimal size\n",
    "#                 first = False\n",
    "\n",
    "#     outfile.write(\"\\n]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path  = os.path.join(output_dir, \"ztf_alert_20240728.json\")\n",
    "# output_path = os.path.join(output_dir, \"day1_ztf_alert_20240728_min.json\")\n",
    "\n",
    "# with open(input_path, \"r\") as f:\n",
    "#     alerts = json.load(f)\n",
    "\n",
    "# # important keys\n",
    "# keep_keys = [\"objectId\", \"candid\", \"candidate\"]  \n",
    "\n",
    "# # filtering\n",
    "# filtered_alerts = [\n",
    "#     {k: alert[k] for k in keep_keys if k in alert}\n",
    "#     for alert in alerts\n",
    "# ]\n",
    "\n",
    "# # output as json\n",
    "# with open(output_path, \"w\") as f:\n",
    "#     json.dump(filtered_alerts, f, separators=(\",\", \":\")) # save as minimum size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc45697",
   "metadata": {},
   "source": [
    "Now let’s take a look at the full set of alerts from one night.\n",
    "Load `day1_ztf_alert_20240728_min.json`! (here, we load it as pandas DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a81270",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_path = os.path.join(output_dir, \"day1_ztf_alert_20240728_min.json\")\n",
    "with open(alert_path, \"r\") as f:\n",
    "    alerts = json.load(f)\n",
    "\n",
    "# flatten the nested JSON structure into a pandas DataFrame using `pd.json_normalize()`.\n",
    "alerts = pd.json_normalize(alerts, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a33b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380a05f",
   "metadata": {},
   "source": [
    "How many alerts are reported on 2024/Jul/28?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931df4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of alerts on 20240728: {len(alerts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39312c",
   "metadata": {},
   "source": [
    "You can now see how many transients ZTF discovers and reports in every night!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c898b4",
   "metadata": {},
   "source": [
    "## Step 1-3: Visualizing the ZTF Alert and Statistics\n",
    "\n",
    "We have now obtained all the alert data reported in a single night. Let’s take a look at some basic statistics of these alerts.\n",
    "\n",
    "First, let’s plot the sky positions of the reported alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3777a",
   "metadata": {},
   "source": [
    "`plot_alert_density(df, ra_col=\"candidate_ra\", dec_col=\"candidate_dec\", nbins=50, cmap=\"YlGn\", title=\"ZTF alerts\", log=False)`\n",
    "\n",
    "Visualize the sky distribution of alerts using a Mollweide projection and a 2D RA/Dec histogram.\n",
    "\n",
    "Arguments:\n",
    "- `df` (pandas.DataFrame): DataFrame containing sky positions (RA and Dec) of ZTF alerts.\n",
    "- `ra_col` (str): Name of the column containing Right Ascension in degrees (default: `\"candidate_ra\"`).\n",
    "- `dec_col` (str): Name of the column containing Declination in degrees (default: `\"candidate_dec\"`).\n",
    "- `nbins` (int): Number of bins for the RA and Dec histogram (default: 50).\n",
    "- `cmap` (str): Colormap for the density map (default: `\"YlGn\"`).\n",
    "- `title` (str): Title for the plot (default: `\"ZTF alerts\"`).\n",
    "- `log` (bool): Whether to apply logarithmic scaling to the density map (default: `False`).\n",
    "\n",
    "Returns:\n",
    "- `None`: Displays a Mollweide projection plot showing the density of alerts on the sky (RA is wrapped to [-$\\pi$, $\\pi$])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alert_density(df, ra_col=\"candidate_ra\", dec_col=\"candidate_dec\",\n",
    "                        nbins=50, cmap=\"YlGn\", title=\"ZTF alerts\", log=False):\n",
    "\n",
    "    # Extract RA and Dec values from the DataFrame and convert to SkyCoord\n",
    "    ra = df[ra_col].values\n",
    "    dec = df[dec_col].values\n",
    "    coords = SkyCoord(ra=ra * u.deg, dec=dec * u.deg, frame='icrs')\n",
    "\n",
    "    # Convert RA to radians in the range [-pi, pi] for Mollweide projection\n",
    "    ra_rad = np.remainder(coords.ra.radian + 2*np.pi, 2*np.pi)\n",
    "    ra_rad[ra_rad > np.pi] -= 2*np.pi\n",
    "    dec_rad = coords.dec.radian\n",
    "\n",
    "    # Compute 2D histogram (RA vs. Dec) for number density\n",
    "    H, xedges, yedges = np.histogram2d(ra_rad, dec_rad, bins=nbins)\n",
    "\n",
    "    # Transpose and vertically flip for proper Mollweide orientation\n",
    "    H = H.T[::-1, :]\n",
    "\n",
    "    # Create a Mollweide projection figure\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = plt.subplot(111, projection=\"mollweide\")\n",
    "\n",
    "    # Define plot boundaries\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    # Apply log scale if requested, mask zero values to avoid log(0)\n",
    "    H_masked = np.where(H == 0, np.nan, H)\n",
    "    if log:\n",
    "        im = ax.imshow(\n",
    "            H_masked,\n",
    "            extent=extent,\n",
    "            cmap=cmap,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"nearest\",\n",
    "            norm=LogNorm(vmin=1, vmax=H.max())\n",
    "        )\n",
    "    else:\n",
    "        im = ax.imshow(\n",
    "            H_masked,\n",
    "            extent=extent,\n",
    "            cmap=cmap,\n",
    "            aspect=\"auto\",\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=1\n",
    "        )\n",
    "\n",
    "    # Add title and grid\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add colorbar to show density scale\n",
    "    plt.colorbar(im, ax=ax, orientation=\"horizontal\", label=\"Alert density\", shrink=0.7, pad=0.07)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the date into each band.\n",
    "alert_g = alerts[(alerts[\"candidate_fid\"] == 1)]\n",
    "alert_r = alerts[(alerts[\"candidate_fid\"] == 2)]\n",
    "\n",
    "plot_alert_density(alert_g, nbins=100, cmap=\"YlGn\", title=\"ZTF g-band alerts\", log=True)\n",
    "plot_alert_density(alert_r, nbins=100, cmap=\"OrRd\", title=\"ZTF r-band alerts\", log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a24afe",
   "metadata": {},
   "source": [
    "This will give you a sense of how wide an area ZTF observes in one night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e168b",
   "metadata": {},
   "source": [
    "According to the official report, the ZTF limiting magnitude is approximately $\\sim 20.5$ mag. You can check the statistical limiting magnitude for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9172066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alert_g['candidate_diffmaglim'], bins=50, density=True)\n",
    "\n",
    "# gaussian fitting\n",
    "mu, std = norm.fit(alert_g['candidate_diffmaglim'])\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Gaussian fit')\n",
    "\n",
    "# mean value\n",
    "plt.axvline(mu, color='red', linestyle='--', label=f'Mean: {mu:.2f} mag')\n",
    "\n",
    "plt.xlabel('Diffmaglim (g-band)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean limiting mag: {mu:.2f} mag\")\n",
    "print(f\"Standard deviation: {std:.2f} mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6edee",
   "metadata": {},
   "source": [
    "This is consistent with the ZTF reports.\n",
    "As an additional check, we also examine the FWHM, whose mean value is $\\sim 2$ sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alert_g['candidate_fwhm'], bins=50, density=True)\n",
    "plt.axvline(alert_g['candidate_fwhm'].mean(), linestyle='--', color='red')\n",
    "plt.xlabel('FWHM')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean FWHM: {alert_g['candidate_fwhm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0db7e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2920581",
   "metadata": {},
   "source": [
    "# Step 2: Hunting Transients\n",
    "\n",
    "In Step 1, we learned the basic structure of a ZTF alert.\n",
    "\n",
    "The next step is to explore how we can search for transients of interest using the information provided in the alerts.\n",
    "\n",
    "Fortunately, ZTF alerts include a variety of useful flags and quality indicators.\n",
    "By utilizing these flags, we can begin filtering the alerts to identify real transients (e.g., supernovae, TDEs, AGN, ...).\n",
    "\n",
    "Let’s try using these features to find candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0695eb5",
   "metadata": {},
   "source": [
    "## Step 2-1: Select Possible SN-like Transients from the ZTF Alerts Observed on 20240728"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e95f8",
   "metadata": {},
   "source": [
    "`candidate` contains a number of informative flags and parameters that help assess the reliability and properties of the detection.\n",
    "\n",
    "The most simple and strong flag is `drb`: Real–Bogus score (closer to 1 means more likely to be real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b32864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alerts['candidate_drb'], bins=50)\n",
    "plt.xlabel('DRB score')\n",
    "plt.ylabel('Numbers')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba891f",
   "metadata": {},
   "source": [
    "If the detections correspond to real objects, the flag value will be close to 1.\n",
    "Here, we adopt a threshold of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_drb = alerts['candidate_drb'] > 0.9\n",
    "print(f\"Alerts filtered by DRB: {mask_drb.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3542be",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656b4fb",
   "metadata": {},
   "source": [
    "## Assignment 1: Combine Flags to Filter SN-like Transients\n",
    "\n",
    "Using `drb` flag alone, we filtered out 157,711 candidates from over 200,000 alerts.\n",
    "\n",
    "In addition to the flags introduced here, ZTF alert data include many other useful flags.\n",
    "\n",
    "Your task here is to design and apply your own set of filters to select SN-like transients! (Please look up the flag names and their meanings on your own.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8689e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f44599",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_SN = (mask_drb & ... & ...)\n",
    "\n",
    "SN = alerts[mask_SN]\n",
    "print(f\"Number of SN-like candidates: {len(SN)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175bd62",
   "metadata": {},
   "source": [
    "If you set the filters appropriately, you should be able to narrow it down to $\\sim 100$ objects.\n",
    "\n",
    "Once you think you've narrowed down the sample appropriately, proceed to the next step! (We will return to this in Step 4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e94569",
   "metadata": {},
   "source": [
    "Let's plot the position of SN candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_g = SN[SN['candidate_fid']==1]\n",
    "SN_r = SN[SN['candidate_fid']==2]\n",
    "\n",
    "plot_alert_density(SN_g, nbins=30, cmap=\"YlGn\")\n",
    "plot_alert_density(SN_r, nbins=30, cmap=\"OrRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced87e23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ad4d4",
   "metadata": {},
   "source": [
    "# Step3: Utilizing the ZTF Brokers\n",
    "\n",
    "So far, we have worked with the ZTF public alerts directly.\n",
    "However, as we have seen, handling raw public alerts can be challenging due to the large data volume and complex format.\n",
    "\n",
    "To address this challenge, Brokers play an important role.\n",
    "Brokers process and reformat alert data to make it more accessible and easier to use for the scientific community.\n",
    "\n",
    "In this step, we will use a broker to dig deeper into the alerts we examined earlier, and learn how to leverage broker-added features for scientific analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc8ca4",
   "metadata": {},
   "source": [
    "## ALeRCE\n",
    "\n",
    "[ALeRCE (Automatic Learning for the Rapid Classification of Events)](https://alerce.science/) is a real-time broker which is processing the alert stream from ZTF and which aims to become a Community Broker for the LSST survey.\n",
    "\n",
    "ALeRCE provides a lot of powerful infromation like:\n",
    "\n",
    "- Cross-matches with external catalogs (e.g., Pan-STARRS, Gaia)\n",
    "- Light curves\n",
    "- light curve classification using machine learning\n",
    "- **Public APIs for query and data access**\n",
    "\n",
    "Indeed, there are several brokers such as [Fink](https://fink-portal.org/ZTF) or [Lasair](https://lasair-ztf.lsst.ac.uk/), but they are not completely public.\n",
    "\n",
    "So, hereafter, let's use the ALeRCE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28976eb6",
   "metadata": {},
   "source": [
    "ALeRCE has already prepared several important tasks as API (see [Link](https://alerce.readthedocs.io/en/latest/)).\n",
    "\n",
    "Let's try several basic task of ALeRCE API !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c9d97",
   "metadata": {},
   "source": [
    "## Step 3-1: Try `query_objects`\n",
    "\n",
    "One of the main features of the ALeRCE API is the query_objects method.\n",
    "\n",
    "This method allows you to retrieve metadata about a ZTF object, such as its ZTF name, RA, Dec, and more.\n",
    "\n",
    "But the most interesting part is that ALeRCE also provides machine learning-based classification results for each object.\n",
    "\n",
    "For example, querying an object can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "mjd_start = Time(\"2024-01-01T00:00:00\", format=\"isot\", scale=\"utc\").mjd\n",
    "\n",
    "QUERY_KW = {'classifier': \"LC_classifier_ATAT_forced_phot(beta)\", # classifer name\n",
    "            \"probability\": 0.9, # lower limit of the estimated probability\n",
    "            \"ndet\": 10, # minimum detection number\n",
    "            \"firstmjd\": mjd_start, # servey range\n",
    "            \"page_size\": 1000, # maximum number of objects\n",
    "            \"format\": \"pandas\" # data format\n",
    "            }\n",
    "query_table = alerce.query_objects(**QUERY_KW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c4ba2",
   "metadata": {},
   "source": [
    "What date is stored in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca605bfe",
   "metadata": {},
   "source": [
    "In particular, `class`, `classifier`, and `probability` are unique to ALeRCE.\n",
    "By using this information, we can quickly identify interesting objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe593da0",
   "metadata": {},
   "source": [
    "As a test, let's visualize a fraction of each `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c343011",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "class_counts = query_table['class'].value_counts()\n",
    "ax.pie(class_counts, labels=class_counts.index, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4477c8d2",
   "metadata": {},
   "source": [
    "Enlerge the small populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cab59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the fractions of each class\n",
    "fig, ax = plt.subplots(figsize = (12,9))\n",
    "query_table_wo_QSO_LPV = query_table[(query_table['class'] != 'QSO') & (query_table['class'] != 'LPV')]\n",
    "class_counts = query_table_wo_QSO_LPV['class'].value_counts()\n",
    "ax.pie(class_counts, labels=class_counts.index, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b0671",
   "metadata": {},
   "source": [
    "ALeRCE equipped several classifer (see `./alerce_classifier.json`). It is interesting to change the method and check the results (homework)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c95167",
   "metadata": {},
   "source": [
    "## Step 3-2: Try `query_lightcurve`\n",
    "\n",
    "Another important feature of the ALeRCE API is `query_lightcurve`.\n",
    "\n",
    "This method returns the light curve of a given object, including both detections and non-detection points, similar to `prv_candidates` in the public ZTF alerts.\n",
    "\n",
    "You can retrieve a light curve easily by searching with the ZTF object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "ztf_name = 'ZTF23aaklqou'\n",
    "lc_example = alerce.query_lightcurve(oid=ztf_name, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06128f1",
   "metadata": {},
   "source": [
    "What is stored in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99326990",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_example['detections'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef81b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_example['non_detections'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6278b4",
   "metadata": {},
   "source": [
    "- `detections`: similar format of `'prv_candidates'`\n",
    "- `non_detections`: only include `mjd`, `fid`, and `diffmaglim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d71e60",
   "metadata": {},
   "source": [
    "Futhermore, they have a similar function of `query_forced_photometry` to access the forced photometries of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5406e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_example = alerce.query_forced_photometry(oid=ztf_name, format=\"json\")\n",
    "fp_example[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5db54a",
   "metadata": {},
   "source": [
    "For the next step, store the queried light curve data as one dict style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = {'detections': lc_example.get('detections', []),\n",
    "                 'non_detections': lc_example.get('non_detections', []),\n",
    "                 'forced_detections': fp_example if isinstance(fp_example, list) else []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a762f",
   "metadata": {},
   "source": [
    "Let's plot the queried light curve!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e14a6e",
   "metadata": {},
   "source": [
    "`plot_alerce_lightcurve(data_json, plot_detections=True, plot_non_detections=True, plot_forced_detections=False, mjd_range=None)`\n",
    "\n",
    "Plot the light curve from an ALeRCE-style alert JSON dictionary, including both detections and non-detections across available filters.\n",
    "\n",
    "Arguments:\n",
    "- `data_json (dict)`: ALeRCE lightcurve JSON data.\n",
    "  - `plot_detections (bool)`: Whether to plot normal detections.\n",
    "  - `plot_non_detections (bool)`: Whether to plot non-detections.\n",
    "  - `plot_forced_detections (bool)`: Whether to plot forced photometry points.\n",
    "  - `mjd_range (tuple)`: Optional (min, max) range for MJD x-axis.\n",
    "\n",
    "Returns:\n",
    "- `None`: Displays a Matplotlib light curve with magnitude vs. MJD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d991586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alerce_lightcurve(data_json, \n",
    "                           plot_detections=True, plot_non_detections=True, plot_forced_detections=False, \n",
    "                           mjd_range=None):\n",
    "\n",
    "    if plot_detections:\n",
    "        detections = data_json.get('detections', [])\n",
    "    if plot_non_detections:\n",
    "        non_detections = data_json.get('non_detections', [])\n",
    "    if plot_forced_detections:\n",
    "        forced_detections = data_json.get('forced_detections', [])\n",
    "\n",
    "    # Filter ID mappings: fid = 1 (g), 2 (r), 3 (i)\n",
    "    band_colors = {1: 'green', 2: 'red', 3: 'orange'}\n",
    "    band_labels = {1: 'g-band', 2: 'r-band', 3: 'i-band'}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # --- Plot standard detections ---\n",
    "    if plot_detections and len(detections) > 0:\n",
    "        for fid in sorted(set(d['fid'] for d in detections if 'fid' in d)):\n",
    "            band_data = [\n",
    "                d for d in detections\n",
    "                if d.get('fid') == fid and 'magpsf' in d and 'sigmapsf' in d\n",
    "            ]\n",
    "            if not band_data:\n",
    "                continue\n",
    "\n",
    "            mjd = [d['mjd'] for d in band_data]\n",
    "            mag = [d['magpsf'] for d in band_data]\n",
    "            err = [d['sigmapsf'] for d in band_data]\n",
    "\n",
    "            ax.errorbar(\n",
    "                mjd, mag, yerr=err,\n",
    "                fmt='o', color=band_colors.get(fid, 'gray'),\n",
    "                label=f'detections ({band_labels.get(fid, f\"band {fid}\")})',\n",
    "                markersize=5, linewidth=1\n",
    "            )\n",
    "\n",
    "    # --- Plot non-detections ---\n",
    "    if plot_non_detections and len(non_detections) > 0:\n",
    "        for fid in sorted(set(d['fid'] for d in non_detections if 'fid' in d and 'diffmaglim' in d)):\n",
    "            band_data = [\n",
    "                d for d in non_detections\n",
    "                if d['fid'] == fid and 'diffmaglim' in d\n",
    "            ]\n",
    "            mjd = [d['mjd'] for d in band_data]\n",
    "            mag = [d['diffmaglim'] for d in band_data]\n",
    "\n",
    "            ax.scatter(\n",
    "                mjd, mag,\n",
    "                marker='v', color=band_colors.get(fid, 'gray'),\n",
    "                alpha=0.2,\n",
    "                label=f'non-detections ({band_labels.get(fid, f\"band {fid}\")})'\n",
    "            )\n",
    "\n",
    "    # --- Plot forced photometry points ---\n",
    "    if plot_forced_detections and len(forced_detections) > 0:\n",
    "        for fid in sorted(set(d['fid'] for d in forced_detections if 'fid' in d)):\n",
    "            band_data = [\n",
    "                d for d in forced_detections\n",
    "                if d.get('fid') == fid and 'mag' in d and 'e_mag' in d\n",
    "            ]\n",
    "            if not band_data:\n",
    "                continue\n",
    "\n",
    "            mjd = [d['mjd'] for d in band_data]\n",
    "            mag = [d['mag'] for d in band_data]\n",
    "            err = [d['e_mag'] for d in band_data]\n",
    "\n",
    "            ax.errorbar(\n",
    "                mjd, mag, yerr=err,\n",
    "                fmt='s', color=band_colors.get(fid, 'gray'),\n",
    "                label=f'forced ({band_labels.get(fid, f\"band {fid}\")})',\n",
    "                markersize=5, linewidth=1, mfc='none'  # hollow square\n",
    "            )\n",
    "\n",
    "    # --- Plot formatting ---\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(\"Magnitude\")\n",
    "    if mjd_range is not None:\n",
    "        ax.set_xlim(left=mjd_range[0], right=mjd_range[1])\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085144b6",
   "metadata": {},
   "source": [
    "Plot `detections` and `non_detections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alerce_lightcurve(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5adbd",
   "metadata": {},
   "source": [
    "Including the forced photometry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0df057",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alerce_lightcurve(combined_data, plot_forced_detections=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94520dc0",
   "metadata": {},
   "source": [
    "Using ALeRCE, we can easily access and handle the ZTF light curve data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34daecb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2722cc",
   "metadata": {},
   "source": [
    "# Step 4: Combining between the ZTF Alerts and Brokers\n",
    "\n",
    "We filtered SN-like transients in Step 2.\n",
    "Let's check whether the selection worked well by examining their light curves using ALeRCE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f50c0",
   "metadata": {},
   "source": [
    "## Step 4-1: Query several light curves selected in Step2, and plot the light curve\n",
    "\n",
    "Let's plot the selected light curves.\n",
    "If our selection criteria are appropriate, the resulting light curves should resemble those of SN-like transients.\n",
    "\n",
    "Randomly sample a ZTF name from the filtered alerts and plot its light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztf_name = SN_g['objectId'].sample(1).iloc[0] \n",
    "lc_example = alerce.query_lightcurve(oid=ztf_name, format=\"json\")\n",
    "fp_example = alerce.query_forced_photometry(oid=ztf_name, format=\"json\")\n",
    "\n",
    "combined_data = {\n",
    "    'detections': lc_example.get('detections', []),\n",
    "    'non_detections': lc_example.get('non_detections', []),\n",
    "    'forced_detections': fp_example if isinstance(fp_example, list) else []\n",
    "}\n",
    "\n",
    "plot_alerce_lightcurve(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d62b3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba308c3",
   "metadata": {},
   "source": [
    "## Assignment 2: Review Your Selected Sample from Step 2 and Refine the Criteria\n",
    "Did you see any supernova-like light curves?\n",
    "If you try plotting several times and no SN-like light curve appears, it likely means that your filtering conditions in Step 2 are not working well.\n",
    "In that case, go back to Step 2, revise your selection criteria, and continue filtering until you can obtain satisfactory SN-like light curves.\n",
    "If the selection appears to be working well, proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccb205",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bd878",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e962dc5",
   "metadata": {},
   "source": [
    "# Step 5: Query the ALeRCE Light Curve Using the Aelected ZTF ID\n",
    "\n",
    "If your selection looks appropriate, you can now query the corresponding ALeRCE light curves and save them to: `./output_day1/lc_alerce/`.\n",
    "\n",
    "**Note: This process may take several minutes to complete, so it is recommended to limit the number of objects to fewer than 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a674ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_dir = os.path.join(output_dir, \"lc_alerce\")\n",
    "os.makedirs(lc_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c7b1f",
   "metadata": {},
   "source": [
    "`fetch_alerce_lightcurves(oids, output_dir, max_retries=3, sleep_time=1.0, retry_wait=2.0, return_errors=False)`\n",
    "\n",
    "Fetch lightcurve and forced photometry data from ALeRCE API and save to JSON files.\n",
    "\n",
    "Arguments\n",
    "- `oids (list of str)`: List of ZTF object IDs (e.g., ['ZTF23abc...', ...]).\n",
    "- `output_dir (str)`: Directory where JSON files will be saved.\n",
    "- `max_retries (int, optional)`: Number of retry attempts per object on failure (default: 3).\n",
    "- `sleep_time (float, optional)`: Seconds to wait between API calls (default: 1.0).\n",
    "- `retry_wait (float, optional)`: Seconds to wait between retries on failure (default: 2.0).\n",
    "- `return_errors (bool)`: flag to save the list of fetching errors.\n",
    "\n",
    "Returns\n",
    "- `list`: List of object IDs that failed to fetch after retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_alerce_lightcurves(oids, output_dir, max_retries=3, sleep_time=1.0, retry_wait=2.0, return_errors=False):\n",
    "\n",
    "    fetching_errors = []\n",
    "\n",
    "    for i, oid in enumerate(oids, 1):\n",
    "        print(f\"[{i}/{len(oids)}] Fetching: {oid}\")\n",
    "        \n",
    "        retries = 0\n",
    "        success = False\n",
    "\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                # Query lightcurve\n",
    "                lc = alerce.query_lightcurve(oid=oid, format=\"json\")\n",
    "                detections = lc.get(\"detections\", [])\n",
    "                non_detections = lc.get(\"non_detections\", [])\n",
    "\n",
    "                # Query forced photometry\n",
    "                fp = alerce.query_forced_photometry(oid=oid, format=\"json\")\n",
    "                forced_detections = fp if isinstance(fp, list) else []\n",
    "\n",
    "                # Combine into one dictionary\n",
    "                combined_data = {\n",
    "                    \"detections\": detections,\n",
    "                    \"non_detections\": non_detections,\n",
    "                    \"forced_detections\": forced_detections,\n",
    "                }\n",
    "\n",
    "                # Save to file\n",
    "                output_path = os.path.join(output_dir, f\"{oid}.json\")\n",
    "                with open(output_path, \"w\") as f:\n",
    "                    json.dump(combined_data, f, indent=2)\n",
    "\n",
    "                success = True\n",
    "                break  # success, exit retry loop\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {oid} (attempt {retries + 1}): {e}\")\n",
    "                retries += 1\n",
    "                time.sleep(retry_wait)\n",
    "\n",
    "        if not success:\n",
    "            fetching_errors.append(oid)\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    if return_errors:\n",
    "        return fetching_errors\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04325cd",
   "metadata": {},
   "source": [
    "Let's query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OIDs\n",
    "oids_to_query = [oid for oid in SN_g[\"objectId\"]]\n",
    "\n",
    "# ~5min for ~50 objects\n",
    "fetch_alerce_lightcurves(oids=oids_to_query, output_dir=lc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64865373",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b578a",
   "metadata": {},
   "source": [
    "# Step 6: Mock Observation with LSST\n",
    "\n",
    "Now, let's perform a mock observation, simulating how LSST would observe the selected objects.\n",
    "\n",
    "The LSST has a significantly deeper limiting magnitude than ZTF; $\\sim 100$ times fainter. However, it also has a longer cadence, typically $\\sim 5$-day baseline.\n",
    "\n",
    "If LSST were observing the same objects detected by ZTF, what would their light curves look like?\n",
    "\n",
    "In this step, we will focus on the g- and r-band light curves, and simulate how LSST might observe them based on its depth and cadence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d9704",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6600a8c",
   "metadata": {},
   "source": [
    "## Assignment 3: Select One Light Curve from Step 5 and Simulate LSST Observations\n",
    "\n",
    "In this assignment, you will select one of the light curves obtained in Step 5 and simulate how it would appear if observed by LSST.\n",
    "\n",
    "We will downsample the ZTF light curve to match the approximate LSST cadence (~5 days).\n",
    "For simplicity, we will neglect the difference in filter transmission between ZTF and LSST filters (this will be addressed in tomorrow’s exercise).\n",
    "\n",
    "Then, we will examine how the light curve would look when observed with LSST's deeper limiting magnitudes.\n",
    "\n",
    "To Do:\n",
    "1. Select one light curve obtained in Step 5\n",
    "2. Interpolate the g- and r-band light curves separately\n",
    "3. Downsample the interpolated light curves to match a 5-day cadence\n",
    "4. Plot the resulting light curves, masking any data fainter than LSST’s limiting magnitudes\n",
    "\n",
    "You can use the helper functions we’ve already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b83ae0",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2da1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f2c93",
   "metadata": {},
   "source": [
    "# Discussions and Further Steps:\n",
    "\n",
    "Today, we worked on handling ZTF alerts and using ALeRCE broker data.\n",
    "\n",
    "If you have extra time, consider exploring the following points:\n",
    "- Try changing the selection criteria in Step 2 to extract different types of objects — such as variable stars, AGNs, tidal disruption events (TDEs), or fast transients.\n",
    "- Get more familiar with the query_objects function in the ALeRCE API, and try to evaluate the number of objects in each class. This could help you estimate event rates for different populations.\n",
    "- **What types of transients or variables might LSST detect that ZTF could not, given LSST’s deeper limiting magnitude and longer cadence?**\n",
    "- **On the other hand, are there any populations that might be detected by ZTF but missed by LSST, due to differences in cadence, depth, or sky coverage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210d431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
